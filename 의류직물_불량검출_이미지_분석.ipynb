{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "의류직물 불량검출_이미지 분석.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "16_s0pU9c-1N2YuaOy509_91v0jPlV5rW",
      "authorship_tag": "ABX9TyO/SI5Jtmz/R49CHTdJuygz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Knowsoeun/AI_Study/blob/main/%EC%9D%98%EB%A5%98%EC%A7%81%EB%AC%BC_%EB%B6%88%EB%9F%89%EA%B2%80%EC%B6%9C_%EC%9D%B4%EB%AF%B8%EC%A7%80_%EB%B6%84%EC%84%9D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "실습 환경 준비"
      ],
      "metadata": {
        "id": "Tu8Kp9u4C4oy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q42mESgtCqjr",
        "outputId": "4b1a9f87-367a-4230-a7d2-667843e35812"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python) (1.21.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xf7yAxPhdHax",
        "outputId": "ae902bb8-a11d-4e44-d3e2-ddb9c9ce2743"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2     #컴퓨터 비전 오픈소스 라이브러리\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import random\n",
        "import string\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "ram5reh8CusO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PATH_DEFECT = '/content/drive/MyDrive/AI스터디/dataset/Defect_images/Defect_images/'\n",
        "PATH_MASK = '/content/drive/MyDrive/AI스터디/dataset/Mask_images/Mask_images/'\n",
        "PATH_NODEFECT = '/content/drive/MyDrive/AI스터디/dataset/NODefect_images/NODefect_images/'"
      ],
      "metadata": {
        "id": "N_Zlhb2AX3Jt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset 불러오기"
      ],
      "metadata": {
        "id": "WIkv7Q73L0hS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(0)\n",
        "\n",
        "defect_list = glob.glob(PATH_DEFECT + '*.png')\n",
        "mask_list = glob.glob(PATH_MASK + '*.png')\n",
        "pass_list = glob.glob(PATH_NODEFECT + '**/*.png')\n",
        "\n",
        "# Match defect-mask pairs\n",
        "new_defect_list = list()\n",
        "new_mask_list = list()\n",
        "for defect in defect_list:\n",
        "    num = defect.split('/')[-1].split('_')[0]\n",
        "    for mask in mask_list:\n",
        "        num_mask = mask.split('/')[-1].split('_')[0]\n",
        "        if num == num_mask:\n",
        "            new_defect_list.append(defect)\n",
        "            new_mask_list.append(mask)\n",
        "            break\n",
        "defect_list = new_defect_list\n",
        "mask_list = new_mask_list"
      ],
      "metadata": {
        "id": "QcI7gBxeLztu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "첫 발송 데이터 생성"
      ],
      "metadata": {
        "id": "5L4P5lTfNKx0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The first dataset given\n",
        "if os.path.exists('/content/drive/MyDrive/AI스터디/dataset/1') is False:\n",
        "    os.mkdir('/content/drive/MyDrive/AI스터디/dataset/1')\n",
        "for file_name in pass_list + defect_list:\n",
        "    if random.randint(0, 9) < 2:\n",
        "        barcode = ''.join(random.choices(string.ascii_letters + string.digits, k=16))\n",
        "        shutil.copy2(file_name, '/content/drive/MyDrive/AI스터디/dataset/1/' + barcode + '.png')"
      ],
      "metadata": {
        "id": "IGPnTlGrL5sR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "두번째 데이터 생성"
      ],
      "metadata": {
        "id": "KvTxmw_nV0AM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The second dataset\n",
        "if os.path.exists('/content/drive/MyDrive/AI스터디/dataset/2') is False:\n",
        "    os.mkdir('/content/drive/MyDrive/AI스터디/dataset/2')\n",
        "if os.path.exists('/content/drive/MyDrive/AI스터디/dataset/2/OK') is False:\n",
        "    os.mkdir('/content/drive/MyDrive/AI스터디/dataset/2/OK')\n",
        "if os.path.exists('/content/drive/MyDrive/AI스터디/dataset/2/FAIL') is False:\n",
        "    os.mkdir('/content/drive/MyDrive/AI스터디/dataset/2/FAIL')\n",
        "idx = 0\n",
        "for file_name in pass_list:\n",
        "    img = cv2.imread(file_name)\n",
        "    height, width, _ = img.shape\n",
        "    step = height // 2\n",
        "\n",
        "    for i in range(width // step):\n",
        "        w = i * step\n",
        "        if w < width - height and random.randint(0, 9) < 2:\n",
        "            patch = img[:, w:w+height, :]\n",
        "            cv2.imwrite('/content/drive/MyDrive/AI스터디/dataset/2/OK/%04d.png' % idx, patch)\n",
        "            idx += 1 \n",
        "\n",
        "patch_list = list()\n",
        "for item in zip(defect_list, mask_list):\n",
        "    defect, mask = item\n",
        "\n",
        "    img_d = cv2.imread(defect)\n",
        "    img_m = cv2.imread(mask)\n",
        "\n",
        "    height, width, _ = img_d.shape\n",
        "    step = height // 2\n",
        "    for i in range(width // step):\n",
        "        w = i * step\n",
        "        if w < width - height:\n",
        "            patch = img_d[:, w:w+height, :]\n",
        "            patch_d = img_m[:, w:w+height, :]\n",
        "            if patch_d.sum() > 0:\n",
        "                patch_list.append(patch)\n",
        "\n",
        "random.shuffle(patch_list)\n",
        "patch_list_fraction = patch_list[:len(patch_list)//3]\n",
        "for idx, patch in enumerate(patch_list_fraction):\n",
        "    cv2.imwrite('/content/drive/MyDrive/AI스터디/dataset/2/FAIL/%04d.png' % idx, patch)"
      ],
      "metadata": {
        "id": "mvFBWjmmVyCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "세번째 데이터 생성"
      ],
      "metadata": {
        "id": "kXvUNMupWFzw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The third dataset\n",
        "if os.path.exists('/content/drive/MyDrive/AI스터디/dataset/3') is False:\n",
        "    os.mkdir('/content/drive/MyDrive/AI스터디/dataset/3')\n",
        "if os.path.exists('/content/drive/MyDrive/AI스터디/dataset/3/OK') is False:\n",
        "    os.mkdir('/content/drive/MyDrive/AI스터디/dataset/3/OK')\n",
        "if os.path.exists('/content/drive/MyDrive/AI스터디/dataset/3/FAIL') is False:\n",
        "    os.mkdir('/content/drive/MyDrive/AI스터디/dataset/3/FAIL')\n",
        "if os.path.exists('/content/drive/MyDrive/AI스터디/dataset/3/MASK') is False:\n",
        "    os.mkdir('/content/drive/MyDrive/AI스터디/dataset/3/MASK')\n",
        "idx = 0\n",
        "for file_name in pass_list:\n",
        "    img = cv2.imread(file_name)\n",
        "    height, width, _ = img.shape\n",
        "    step = height // 2\n",
        "\n",
        "    for i in range(width // step):\n",
        "        w = i * step\n",
        "        if w < width - height and random.randint(0, 9) < 3:\n",
        "            patch = img[:, w:w+height, :]\n",
        "            cv2.imwrite('/content/drive/MyDrive/AI스터디/dataset/3/OK/%04d.png' % idx, patch)\n",
        "            idx += 1 \n",
        "\n",
        "patch_pair_list = list()\n",
        "for item in zip(defect_list, mask_list):\n",
        "    defect, mask = item\n",
        "\n",
        "    img_d = cv2.imread(defect)\n",
        "    img_m = cv2.imread(mask)\n",
        "\n",
        "    height, width, _ = img_d.shape\n",
        "    step = height // 2\n",
        "    for i in range(width // step):\n",
        "        w = i * step\n",
        "        if w < width - height:\n",
        "            patch = img_d[:, w:w+height, :]\n",
        "            patch_d = img_m[:, w:w+height, :]\n",
        "\n",
        "            if patch_d.sum() > 0:\n",
        "                patch_pair_list.append((patch, patch_d))\n",
        "\n",
        "random.shuffle(patch_pair_list)\n",
        "for idx, pair in enumerate(patch_pair_list):\n",
        "    patch, patch_d = pair\n",
        "    cv2.imwrite('/content/drive/MyDrive/AI스터디/dataset/3/FAIL/%04d.png' % idx, patch)\n",
        "    cv2.imwrite('/content/drive/MyDrive/AI스터디/dataset/3/MASK/%04d.png' % idx, patch_d)"
      ],
      "metadata": {
        "id": "ouAAjB49YfIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "실전 데이터 생성"
      ],
      "metadata": {
        "id": "Du02GPRQWHN3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The test dataset\n",
        "if os.path.exists('/content/drive/MyDrive/AI스터디/data/') is False:\n",
        "    os.mkdir('/content/drive/MyDrive/AI스터디/data/')\n",
        "if os.path.exists('/content/drive/MyDrive/AI스터디/tfrecords/') is False:\n",
        "    os.mkdir('/content/drive/MyDrive/AI스터디/tfrecords/')\n",
        "if os.path.exists('/content/drive/MyDrive/AI스터디/model/') is False:\n",
        "    os.mkdir('/content/drive/MyDrive/AI스터디/model/')\n",
        "if os.path.exists('/content/drive/MyDrive/AI스터디/data/input_data') is False:\n",
        "    os.mkdir('/content/drive/MyDrive/AI스터디/data/input_data')\n",
        "if os.path.exists('/content/drive/MyDrive/AI스터디/data/output_csv') is False:\n",
        "    os.mkdir('/content/drive/MyDrive/AI스터디/data/output_csv')\n",
        "    \n",
        "idx = 0\n",
        "for file_name in pass_list:\n",
        "    img = cv2.imread(file_name)\n",
        "    height, width, _ = img.shape\n",
        "    step = height // 2\n",
        "\n",
        "    for i in range(width // step):\n",
        "        w = i * step\n",
        "        if w < width - height and random.randint(0, 9) < 5:\n",
        "            patch = img[:, w:w+height, :]\n",
        "            cv2.imwrite('/content/drive/MyDrive/AI스터디/data/input_data/ok_%04d.png' % idx, patch)\n",
        "            idx += 1 \n",
        "\n",
        "patch_pair_list = list()\n",
        "for item in zip(defect_list, mask_list):\n",
        "    defect, mask = item\n",
        "\n",
        "    img_d = cv2.imread(defect)\n",
        "    img_m = cv2.imread(mask)\n",
        "\n",
        "    height, width, _ = img_d.shape\n",
        "    step = height // 2\n",
        "    for i in range(width // step):\n",
        "        w = i * step\n",
        "        if w < width - height:\n",
        "            patch = img_d[:, w:w+height, :]\n",
        "            patch_d = img_m[:, w:w+height, :]\n",
        "\n",
        "            if patch_d.sum() > 0:\n",
        "                patch_pair_list.append((patch, patch_d))\n",
        "\n",
        "random.shuffle(patch_pair_list)\n",
        "for idx, pair in enumerate(patch_pair_list):\n",
        "    patch, patch_d = pair\n",
        "    cv2.imwrite('/content/drive/MyDrive/AI스터디/data/input_data/fail_%04d.png' % idx, patch)"
      ],
      "metadata": {
        "id": "6mlvcPQaWWSl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "실행 가능성 확인하기"
      ],
      "metadata": {
        "id": "qVf3vlELbHFR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "metadata": {
        "id": "OGSN2XQBcMXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "하이퍼파라미터"
      ],
      "metadata": {
        "id": "Xd5Kua-vbecn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 15  # 학습이 너무 느려서 15로 설정함\n",
        "\n",
        "DATASET_PATH = '/content/drive/MyDrive/AI스터디/dataset/2/'\n",
        "DATASET_OK_PATTERN = DATASET_PATH + 'OK/*.png'     # 정상\n",
        "DATASET_FAIL_PATTERN = DATASET_PATH + 'FAIL/*.png'  # 불량\n",
        "\n",
        "RESULT_SAVE_PATH = '/content/drive/MyDrive/AI스터디/results/'  # 알고리즘 결과"
      ],
      "metadata": {
        "id": "SnJQ62edNRwk"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "단순한 모델 설정"
      ],
      "metadata": {
        "id": "rUMXxH0zbsFM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Model():\n",
        "    return Sequential([Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 1)), #tensorflow 버전업으로 코드 변경\n",
        "                       MaxPool2D(),\n",
        "                       Conv2D(64, (3, 3), activation='relu'),\n",
        "                       MaxPool2D(),\n",
        "                       Conv2D(128, (3, 3), activation='relu'),\n",
        "                       MaxPool2D(),\n",
        "                       Conv2D(256, (3, 3), activation='relu'),\n",
        "                       MaxPool2D(),\n",
        "                       Flatten(),\n",
        "                       Dense(1, activation='sigmoid')])"
      ],
      "metadata": {
        "id": "JKK5GmHoXV08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터셋 불러오기"
      ],
      "metadata": {
        "id": "WQEcFUZabvkV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(file_name):\n",
        "    img = tf.io.read_file(file_name)\n",
        "    img = tf.image.decode_png(img, channels=1) #tensorflow 버전업으로 코드 변경\n",
        "    return tf.image.convert_image_dtype(img, tf.float32)"
      ],
      "metadata": {
        "id": "VUM63p2FbIeG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ok_list = glob.glob(DATASET_OK_PATTERN)\n",
        "ds_ok = tf.data.Dataset.list_files(ok_list)\n",
        "ds_ok_label = tf.data.Dataset.from_tensor_slices([0] * len(ok_list))\n",
        "\n",
        "ds_ok = ds_ok.map(preprocess)\n",
        "ds_ok = tf.data.Dataset.zip((ds_ok, ds_ok_label))\n",
        "\n",
        "fail_list = glob.glob(DATASET_FAIL_PATTERN)\n",
        "ds_fail = tf.data.Dataset.list_files(fail_list)\n",
        "ds_fail_label = tf.data.Dataset.from_tensor_slices([1] * len(fail_list))\n",
        "\n",
        "ds_fail = ds_fail.map(preprocess)\n",
        "ds_fail = tf.data.Dataset.zip((ds_fail, ds_fail_label))\n",
        "\n",
        "ds = tf.data.Dataset.concatenate(ds_ok, ds_fail)"
      ],
      "metadata": {
        "id": "6iW3_2IKP2o0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train, Valid 데이터셋 나누기"
      ],
      "metadata": {
        "id": "zlkj_J6lY0TI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds_size = len(ok_list) + len(fail_list)\n",
        "train_size = int(ds_size * 0.7)\n",
        "\n",
        "ds = ds.shuffle(ds_size)\n",
        "ds_train = ds.take(train_size).shuffle(1024, reshuffle_each_iteration=True).batch(32)\n",
        "ds_valid = ds.skip(train_size).batch(32)"
      ],
      "metadata": {
        "id": "Edg1jwhLcgEW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 생성 및 학습"
      ],
      "metadata": {
        "id": "J6MiRoO2Y4QW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model()\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "1BPa5JrEY21Y"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(ds_train, validation_data=ds_valid, epochs=EPOCHS)\n",
        "# Training 시키니 loss가 0.45에서 0.36으로 지속적으로 감소하였다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctcm9P6XY55w",
        "outputId": "438ae181-5f91-4546-d17d-594faee4e71a"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "21/21 [==============================] - 107s 5s/step - loss: 0.3403 - accuracy: 0.8805 - val_loss: 0.3178 - val_accuracy: 0.8908\n",
            "Epoch 2/15\n",
            "21/21 [==============================] - 106s 5s/step - loss: 0.3766 - accuracy: 0.8638 - val_loss: 0.3460 - val_accuracy: 0.8627\n",
            "Epoch 3/15\n",
            "21/21 [==============================] - 106s 5s/step - loss: 0.3371 - accuracy: 0.8865 - val_loss: 0.4077 - val_accuracy: 0.9049\n",
            "Epoch 4/15\n",
            "21/21 [==============================] - 107s 5s/step - loss: 0.3422 - accuracy: 0.8911 - val_loss: 0.3291 - val_accuracy: 0.8979\n",
            "Epoch 5/15\n",
            "21/21 [==============================] - 106s 5s/step - loss: 0.3354 - accuracy: 0.8654 - val_loss: 0.3893 - val_accuracy: 0.8732\n",
            "Epoch 6/15\n",
            "21/21 [==============================] - 107s 5s/step - loss: 0.3151 - accuracy: 0.8971 - val_loss: 0.2713 - val_accuracy: 0.9155\n",
            "Epoch 7/15\n",
            "21/21 [==============================] - 106s 5s/step - loss: 0.3017 - accuracy: 0.8926 - val_loss: 0.2986 - val_accuracy: 0.8768\n",
            "Epoch 8/15\n",
            "21/21 [==============================] - 107s 5s/step - loss: 0.3134 - accuracy: 0.8835 - val_loss: 0.3098 - val_accuracy: 0.8908\n",
            "Epoch 9/15\n",
            "21/21 [==============================] - 106s 5s/step - loss: 0.3504 - accuracy: 0.8699 - val_loss: 0.3608 - val_accuracy: 0.8838\n",
            "Epoch 10/15\n",
            "21/21 [==============================] - 106s 5s/step - loss: 0.3438 - accuracy: 0.8896 - val_loss: 0.3185 - val_accuracy: 0.8838\n",
            "Epoch 11/15\n",
            "21/21 [==============================] - 108s 5s/step - loss: 0.3146 - accuracy: 0.8850 - val_loss: 0.3658 - val_accuracy: 0.8732\n",
            "Epoch 12/15\n",
            "21/21 [==============================] - 110s 5s/step - loss: 0.3046 - accuracy: 0.8865 - val_loss: 0.3432 - val_accuracy: 0.8662\n",
            "Epoch 13/15\n",
            "21/21 [==============================] - 113s 5s/step - loss: 0.3147 - accuracy: 0.8896 - val_loss: 0.3047 - val_accuracy: 0.9225\n",
            "Epoch 14/15\n",
            "21/21 [==============================] - 109s 5s/step - loss: 0.3042 - accuracy: 0.8926 - val_loss: 0.4509 - val_accuracy: 0.8521\n",
            "Epoch 15/15\n",
            "21/21 [==============================] - 108s 5s/step - loss: 0.3537 - accuracy: 0.8775 - val_loss: 0.2967 - val_accuracy: 0.8979\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f58baabb110>"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "결과를 이미지로 저장"
      ],
      "metadata": {
        "id": "qjTfwjgkY7p_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mkdir(path):\n",
        "    if os.path.exists(path) is False:\n",
        "        os.mkdir(path)\n",
        "\n",
        "mkdir(RESULT_SAVE_PATH)\n",
        "mkdir(RESULT_SAVE_PATH + '/TP')  # True Positive\n",
        "mkdir(RESULT_SAVE_PATH + '/TN')  # True Negative\n",
        "mkdir(RESULT_SAVE_PATH + '/FP')  # False Positive \n",
        "mkdir(RESULT_SAVE_PATH + '/FN')  # False Negative \n",
        "\n",
        "index = 0\n",
        "for imgs, labels in ds_valid:\n",
        "    preds = model.predict(imgs)\n",
        "    for idx in range(imgs.shape[0]):\n",
        "        gt = labels[idx].numpy()\n",
        "        y = preds[idx]\n",
        "        \n",
        "        if gt == 1 and y > 0.5:\n",
        "            path = RESULT_SAVE_PATH + '/TP' # 제대로 검출한 것들(불량 검출)-1에 가까워야 잘 검출된 것이다.\n",
        "        elif gt == 1 and y <= 0.5:\n",
        "            path = RESULT_SAVE_PATH + '/FN' # 양품이라고 했는데 실제로 불량이었던 것들. 오검. \n",
        "        elif gt == 0 and y > 0.5:\n",
        "            path = RESULT_SAVE_PATH + '/FP' # 0이므로 오검한 것은 없다.\n",
        "        else:\n",
        "            path = RESULT_SAVE_PATH + '/TN' # 0.5에 가깝게 점수가 높은 것들을 보면 복잡하게 생긴 것들이 많다. \n",
        "                                            # 0.4점대랑 0.1점대랑 구분이 명확하게 되진 않았다.\n",
        "            \n",
        "        cv2.imwrite(path + '/%.4f_%04d.png' % (y, index), imgs[idx].numpy() * 255)\n",
        "        index +=1\n",
        "# 결과 이미지가 저장된 곳을 찾아가서 정밀도와 재현율을 구해보았다.\n",
        "# TP = 2, FN= 33, FP= 0, TN=249\n",
        "# 정밀도 = 1, 재현율 = 0.06"
      ],
      "metadata": {
        "id": "HILpeN87Y603"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " *정밀도*  \n",
        " 2/(2 + 0) = 1  \n",
        " 이를 해석해보자면, ‘불량으로 판정한 양품은 2개인데, 그 중 2명만 실제로 불량인 양품이다’라고 이해할 수 있다.   \n",
        " 따라서, 정밀도 측면에서 이 진단 키트의 정확성은 100%라고 볼 수 있다.\n",
        "\n",
        " "
      ],
      "metadata": {
        "id": "kiQ8kNnP_u5d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*재현율*  \n",
        "\n",
        "(positive 데이터를 negative로 잘못 판단하면 문제가 생기는 경우에 중요시된다.)  \n",
        "(재현율은 예를 들어 암 발병을 판단하는 경우에 암 환자를 음성으로 잘못 판단하는 경우 대가가 크기 때문에 FN을 낮추는데 초점을 맞춰야한다.)  \n",
        "2/(33+0)=0.06    \n",
        "재현율이 1% 미만이므로 좋은 모델이라고 볼 수 있다. "
      ],
      "metadata": {
        "id": "e6gAFnx_AGce"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TFRecord Builder"
      ],
      "metadata": {
        "id": "SE8gNFe1BsPH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import cv2"
      ],
      "metadata": {
        "id": "jg7GXI79_2oS"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paths and Hyperparameters"
      ],
      "metadata": {
        "id": "2xAxZadCBwFw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_OK_PATTERN = '/content/drive/MyDrive/AI스터디/dataset/3/OK/*.png'\n",
        "DATASET_FAIL_PATTERN = '/content/drive/MyDrive/AI스터디/dataset/3/FAIL/*.png'\n",
        "\n",
        "TFRECORD_PATH = '/content/drive/MyDrive/AI스터디/tfrecords/'\n",
        "IMAGE_PER_TFRECORD = 100"
      ],
      "metadata": {
        "id": "l8_xqkPWBtpq"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import data"
      ],
      "metadata": {
        "id": "cxZuK-GAByM_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ok_list = glob.glob(DATASET_OK_PATTERN)\n",
        "fail_list = glob.glob(DATASET_FAIL_PATTERN)\n",
        "\n",
        "num_ok = len(ok_list)\n",
        "num_fail = len(fail_list)\n",
        "\n",
        "# Oversampling\n",
        "fail_list_new = list()\n",
        "for _ in range(num_ok // num_fail):\n",
        "    fail_list_new += fail_list\n",
        "fail_list_new += fail_list[: num_ok % num_fail]\n",
        "fail_list = fail_list_new\n",
        "\n",
        "ok_label = [0] * len(ok_list)\n",
        "fail_label = [1] * len(fail_list)\n",
        "\n",
        "file_list = ok_list + fail_list\n",
        "label_list = ok_label + fail_label"
      ],
      "metadata": {
        "id": "UNkQgWtcBxh4"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TFRecord functions"
      ],
      "metadata": {
        "id": "Cww3S_5AB3Q6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _bytes_feature(value):\n",
        "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
        "    if isinstance(value, type(tf.constant(0))):\n",
        "        value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
        "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "def _int64_feature(value):\n",
        "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
        "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
        "\n",
        "def image_example(image_string, label):\n",
        "    image_shape = tf.image.decode_image(image_string).shape\n",
        "\n",
        "    feature = {\n",
        "        'height': _int64_feature(image_shape[0]),\n",
        "        'width': _int64_feature(image_shape[1]),\n",
        "        'depth': _int64_feature(image_shape[2]),\n",
        "        'label': _int64_feature(label),\n",
        "        'image_raw': _bytes_feature(image_string),\n",
        "    }\n",
        "\n",
        "    return tf.train.Example(features=tf.train.Features(feature=feature))"
      ],
      "metadata": {
        "id": "xUyZClH9B2M3"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write TFRecords"
      ],
      "metadata": {
        "id": "spd66zm9B6fY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.exists(TFRECORD_PATH) is False:\n",
        "    os.mkdir(TFRECORD_PATH)\n",
        "\n",
        "num_tfrecords = len(file_list) // IMAGE_PER_TFRECORD\n",
        "if len(file_list) % IMAGE_PER_TFRECORD != 0:\n",
        "    num_tfrecords += 1\n",
        "\n",
        "for idx in range(num_tfrecords):\n",
        "    idx0 = idx * IMAGE_PER_TFRECORD\n",
        "    idx1 = idx0 + IMAGE_PER_TFRECORD\n",
        "    record_file = TFRECORD_PATH + '%05d.tfrecords' % idx\n",
        "    with tf.io.TFRecordWriter(record_file) as writer:\n",
        "        for filename, label in zip(file_list[idx0:idx1],\n",
        "                                   label_list[idx0:idx1]): # 데이터를 원하는 크기만큼 슬라이싱해서 넣어준다.\n",
        "            image_string = open(filename, 'rb').read()\n",
        "            tf_example = image_example(image_string, label)\n",
        "            writer.write(tf_example.SerializeToString())"
      ],
      "metadata": {
        "id": "X7RShhMGB5qy"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-모델 학습 및 검증하기"
      ],
      "metadata": {
        "id": "Wsq14VCLEDU-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 학습"
      ],
      "metadata": {
        "id": "_t3FPBEADPP3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow-addons"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mcmaho5bEQTs",
        "outputId": "845d371a-b7b6-4c66-acaf-50f0e17d8239"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.16.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[?25l\r\u001b[K     |▎                               | 10 kB 16.0 MB/s eta 0:00:01\r\u001b[K     |▋                               | 20 kB 16.8 MB/s eta 0:00:01\r\u001b[K     |▉                               | 30 kB 10.1 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 40 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 51 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 61 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |██                              | 71 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 81 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 92 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███                             | 102 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 112 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 122 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 133 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████                            | 143 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 153 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 163 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█████                           | 174 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 184 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 194 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 204 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 215 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 225 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 235 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |███████                         | 245 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 256 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 266 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 276 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 286 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 296 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 307 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 317 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 327 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 337 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 348 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 358 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 368 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 378 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 389 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 399 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 409 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 419 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 430 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 440 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 450 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 460 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 471 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 481 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 491 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 501 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 512 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 522 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 532 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 542 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 552 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 563 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 573 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 583 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 593 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 604 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 614 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 624 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 634 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 645 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 655 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 665 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 675 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 686 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 696 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 706 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 716 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 727 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 737 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 747 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 757 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 768 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 778 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 788 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 798 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 808 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 819 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 829 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 839 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 849 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 860 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 870 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 880 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 890 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 901 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 911 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 921 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 931 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 942 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 952 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 962 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 972 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 983 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 993 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.0 MB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.0 MB 5.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.0 MB 5.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.0 MB 5.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.0 MB 5.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.1 MB 5.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.1 MB 5.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.1 MB 5.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.1 MB 5.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.1 MB 5.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.1 MB 5.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.1 MB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1 MB 5.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.16.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Concatenate, Flatten, Dense"
      ],
      "metadata": {
        "id": "H25EKwuAB8sr"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "하이퍼파라미터"
      ],
      "metadata": {
        "id": "7A5sRLCQDZQ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 2 # 너무 오래걸려서 일단 1000대신 2번만 돌린다\n",
        "RESULT_SAVE_PATH = '/content/drive/MyDrive/AI스터디/results/'"
      ],
      "metadata": {
        "id": "ouu82RJfDRd_"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inception-based 모델 정의"
      ],
      "metadata": {
        "id": "aSW8XNdSDeo9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Model():\n",
        "    def inception(filters):\n",
        "        def subnetwork(x):\n",
        "            h1 = Conv2D(filters, (1, 1), padding='same', activation='relu')(x)\n",
        "            h1 = MaxPool2D()(h1)\n",
        "            \n",
        "            h2 = Conv2D(filters // 2, (1, 1), padding='same', activation='relu')(x)\n",
        "            h2 = Conv2D(filters, (3, 3), padding='same', activation='relu')(h2)\n",
        "            h2 = MaxPool2D()(h2)\n",
        "            \n",
        "            h3 = Conv2D(filters // 2, (1, 1), padding='same', activation='relu')(x)\n",
        "            h3 = Conv2D(filters, (5, 5), padding='same', activation='relu')(h3)\n",
        "            h3 = MaxPool2D()(h3)\n",
        "            return Concatenate()([h1, h2, h3])\n",
        "        return subnetwork\n",
        "    \n",
        "    x = tf.keras.Input(shape=(256, 256, 3))\n",
        "    h = inception(16)(x)\n",
        "    h = inception(32)(h)\n",
        "    h = inception(32)(h)\n",
        "    h = inception(32)(h)\n",
        "    h = inception(32)(h)\n",
        "    h = Flatten()(h)\n",
        "    h = Dense(1024, activation='relu')(h)\n",
        "    y = Dense(1, activation='sigmoid')(h)\n",
        "    return tf.keras.Model(inputs=x, outputs=y)"
      ],
      "metadata": {
        "id": "WPE9zypxDeCd"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data 전처리 함수 정의"
      ],
      "metadata": {
        "id": "IShQx1H5DhO5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(img):\n",
        "    return tf.image.convert_image_dtype(img, tf.float32)"
      ],
      "metadata": {
        "id": "4LY6KcGLDg37"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Augmentation 함수 정의"
      ],
      "metadata": {
        "id": "QVRdISyvDj8H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def augmentation(img, label):\n",
        "    def flip(x):\n",
        "        x = tf.image.random_flip_left_right(x)\n",
        "        x = tf.image.random_flip_up_down(x)\n",
        "        return x\n",
        "    \n",
        "    def rotate(x):\n",
        "        x = tf.cond(tf.random.uniform(shape=[], minval=0.0, maxval=1.0, dtype=tf.float32) > 0.5,\n",
        "                   lambda: tfa.image.rotate(x,\n",
        "                                       tf.random.uniform(shape=[], minval=0.0, maxval=360.0, dtype=tf.float32),\n",
        "                                       interpolation='BILINEAR'),\n",
        "                   lambda: x)\n",
        "        return x\n",
        "    \n",
        "    def translation(x):\n",
        "        dx = tf.random.uniform(shape=[], minval=-10.0, maxval=10.0, dtype=tf.float32)\n",
        "        dy = tf.random.uniform(shape=[], minval=-10.0, maxval=10.0, dtype=tf.float32)\n",
        "        x = tf.cond(tf.random.uniform(shape=[], minval=0.0, maxval=1.0, dtype=tf.float32) > 0.5,\n",
        "                    lambda: tfa.image.transform(x,\n",
        "                                                [0, 0, dx, 0, 0, dy, 0, 0],\n",
        "                                                interpolation='BILINEAR'),\n",
        "                    lambda: x)\n",
        "        return x\n",
        "    \n",
        "    img = flip(img)\n",
        "    img = rotate(img)\n",
        "    img = translation(img)\n",
        "           \n",
        "    return img, label"
      ],
      "metadata": {
        "id": "WYQ3TcWPDjau"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TFRecords 불러오기"
      ],
      "metadata": {
        "id": "LuzeZRYqDmmY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tffiles = glob.glob('/content/drive/MyDrive/AI스터디/tfrecords/*')\n",
        "raw_image_dataset = tf.data.TFRecordDataset(tffiles)\n",
        "\n",
        "image_feature_description = {\n",
        "    'height': tf.io.FixedLenFeature([], tf.int64),\n",
        "    'width': tf.io.FixedLenFeature([], tf.int64),\n",
        "    'depth': tf.io.FixedLenFeature([], tf.int64),\n",
        "    'label': tf.io.FixedLenFeature([], tf.int64),\n",
        "    'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
        "}\n",
        "\n",
        "def _parse_image_function(example_proto):\n",
        "    return tf.io.parse_single_example(example_proto, image_feature_description)\n",
        "\n",
        "def _parse_image_label(parsed_dataset):\n",
        "    return preprocess(tf.image.decode_png(parsed_dataset['image_raw'])), parsed_dataset['label']\n",
        "\n",
        "parsed_image_dataset = raw_image_dataset.map(_parse_image_function)\n",
        "dataset = parsed_image_dataset.map(_parse_image_label)"
      ],
      "metadata": {
        "id": "GBlBtEyHDmJY"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터셋 나누기"
      ],
      "metadata": {
        "id": "p1DDe0oSDpkd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds_size = 0\n",
        "for _ in dataset:\n",
        "    ds_size += 1\n",
        "\n",
        "train_size = int(ds_size * 0.7)\n",
        "\n",
        "ds = dataset.shuffle(ds_size)\n",
        "ds_train = ds.take(train_size).shuffle(1024, reshuffle_each_iteration=True).prefetch(1024).batch(32).map(augmentation)\n",
        "ds_valid = ds.skip(train_size).prefetch(1024).batch(32)"
      ],
      "metadata": {
        "id": "w6tViYcvDo_y"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 생성"
      ],
      "metadata": {
        "id": "s4Mp_nSfDsO3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model()\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "6vs4NcjiDrtm"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 학습하기"
      ],
      "metadata": {
        "id": "3-leAPjlDvTi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=30, verbose=1)\n",
        "history = model.fit(ds_train,\n",
        "                    validation_data=ds_valid,\n",
        "                    epochs=EPOCHS,\n",
        "                    callbacks=[earlystopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6076qPrDuKc",
        "outputId": "7cc69d9c-3687-4662-eee4-039fe54cb0b5"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "55/55 [==============================] - 546s 10s/step - loss: 0.6928 - accuracy: 0.4925 - val_loss: 0.6883 - val_accuracy: 0.5027\n",
            "Epoch 2/2\n",
            "55/55 [==============================] - 512s 9s/step - loss: 0.6705 - accuracy: 0.5743 - val_loss: 0.6503 - val_accuracy: 0.6694\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "학습 결과 Plot"
      ],
      "metadata": {
        "id": "tqhthQWjD3kD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(loss, 'ro-')\n",
        "plt.plot(val_loss, 'bo-')\n",
        "plt.ylabel('Cross Entropy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "-LOULb3yD47J",
        "outputId": "15ed8b3e-2a47-4547-fad4-277c06eb79e3"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 저장"
      ],
      "metadata": {
        "id": "kFdCbkvWD6Hg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/AI스터디/model/inception_model.h5')"
      ],
      "metadata": {
        "id": "8FK7OYhXD7wE"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-프로그램 전달하기"
      ],
      "metadata": {
        "id": "MZbwrDhyKJno"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "배치형 동작 프로그램"
      ],
      "metadata": {
        "id": "KQB3ODlIKKqk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from datetime import datetime\n",
        "import time\n",
        "import glob"
      ],
      "metadata": {
        "id": "P7w9-0MhKDAl"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "하이퍼파라미터, Path"
      ],
      "metadata": {
        "id": "FdoTh-dRKO-7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "THRES_LEVEL = 0.5\n",
        "\n",
        "INPUT_PATH = '/content/drive/MyDrive/AI스터디/data/input_data/'\n",
        "CSV_PATH = '/content/drive/MyDrive/AI스터디/data/output_csv/'"
      ],
      "metadata": {
        "id": "vORvbp59KNYB"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 불러오기"
      ],
      "metadata": {
        "id": "yYQ3WmIsKUAk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.load_model('/content/drive/MyDrive/AI스터디/model/inception_model.h5')"
      ],
      "metadata": {
        "id": "zxoInnzIKTid"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "입력 데이터 전처리"
      ],
      "metadata": {
        "id": "2n8_DmRRKZV8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(file_name):\n",
        "    img = tf.io.read_file(file_name)\n",
        "    img = tf.image.decode_image(img)\n",
        "    return tf.image.convert_image_dtype(img, tf.float32)"
      ],
      "metadata": {
        "id": "n_m26e80KXxq"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "입력 데이터 불러오기"
      ],
      "metadata": {
        "id": "rtbkavCeKbIF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_list = glob.glob(INPUT_PATH + '*.png')\n",
        "dataset = tf.data.Dataset.list_files(file_list).map(preprocess)"
      ],
      "metadata": {
        "id": "Olw4Q-6bKake"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "알고리즘 구동 및 CSV 결과 저장"
      ],
      "metadata": {
        "id": "ddOu12ERKemv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "now = datetime.now().strftime('%Y%d%m_%H%M%S')\n",
        "with open(CSV_PATH + now + '.csv', 'w') as f:\n",
        "    for image, filename in zip(dataset, file_list):\n",
        "        image = image[tf.newaxis, ...] # HWC -> NHWC\n",
        "        \n",
        "        a = time.time()\n",
        "        predict = model.predict(image)[0][0]\n",
        "        print('Inference Time:', time.time() - a)\n",
        "        \n",
        "        if predict > THRES_LEVEL:\n",
        "            label = 'FAIL'\n",
        "        else:\n",
        "            label = 'OK'\n",
        "        \n",
        "        f.write(','.join([filename, label, str(predict)]) + '\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbIODkuUKdY-",
        "outputId": "8d6af1b9-6276-4f0b-b6c8-acc0e009dfba"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference Time: 0.772491455078125\n",
            "Inference Time: 0.41195130348205566\n",
            "Inference Time: 0.1836533546447754\n",
            "Inference Time: 0.17984795570373535\n",
            "Inference Time: 0.34670257568359375\n",
            "Inference Time: 0.32506799697875977\n",
            "Inference Time: 0.1891765594482422\n",
            "Inference Time: 0.17984867095947266\n",
            "Inference Time: 0.19922423362731934\n",
            "Inference Time: 0.17654633522033691\n",
            "Inference Time: 0.19945335388183594\n",
            "Inference Time: 0.1694507598876953\n",
            "Inference Time: 0.21660780906677246\n",
            "Inference Time: 0.2104346752166748\n",
            "Inference Time: 0.20618486404418945\n",
            "Inference Time: 0.16701960563659668\n",
            "Inference Time: 0.19171428680419922\n",
            "Inference Time: 0.19443464279174805\n",
            "Inference Time: 0.19825196266174316\n",
            "Inference Time: 0.16107463836669922\n",
            "Inference Time: 0.1967296600341797\n",
            "Inference Time: 0.16438007354736328\n",
            "Inference Time: 0.5985705852508545\n",
            "Inference Time: 0.5065698623657227\n",
            "Inference Time: 0.4689640998840332\n",
            "Inference Time: 0.3763909339904785\n",
            "Inference Time: 0.37769103050231934\n",
            "Inference Time: 0.43079423904418945\n",
            "Inference Time: 0.23757243156433105\n",
            "Inference Time: 0.15579819679260254\n",
            "Inference Time: 0.17609310150146484\n",
            "Inference Time: 0.16330718994140625\n",
            "Inference Time: 0.1935131549835205\n",
            "Inference Time: 0.1634383201599121\n",
            "Inference Time: 0.12014889717102051\n",
            "Inference Time: 0.11022472381591797\n",
            "Inference Time: 0.12130188941955566\n",
            "Inference Time: 0.13837337493896484\n",
            "Inference Time: 0.11843419075012207\n",
            "Inference Time: 0.11328649520874023\n",
            "Inference Time: 0.11580038070678711\n",
            "Inference Time: 0.1200718879699707\n",
            "Inference Time: 0.12802529335021973\n",
            "Inference Time: 0.12359857559204102\n",
            "Inference Time: 0.11662745475769043\n",
            "Inference Time: 0.11266374588012695\n",
            "Inference Time: 0.1368703842163086\n",
            "Inference Time: 0.12648439407348633\n",
            "Inference Time: 0.13892245292663574\n",
            "Inference Time: 0.18163704872131348\n",
            "Inference Time: 0.1960892677307129\n",
            "Inference Time: 0.23540878295898438\n",
            "Inference Time: 0.3145101070404053\n",
            "Inference Time: 0.23695087432861328\n",
            "Inference Time: 0.16384077072143555\n",
            "Inference Time: 0.2517714500427246\n",
            "Inference Time: 0.31119585037231445\n",
            "Inference Time: 0.22222542762756348\n",
            "Inference Time: 0.35117125511169434\n",
            "Inference Time: 0.2793772220611572\n",
            "Inference Time: 0.22266149520874023\n",
            "Inference Time: 0.23934626579284668\n",
            "Inference Time: 0.22376251220703125\n",
            "Inference Time: 0.29065656661987305\n",
            "Inference Time: 0.2359621524810791\n",
            "Inference Time: 0.2352135181427002\n",
            "Inference Time: 0.1833493709564209\n",
            "Inference Time: 0.24885082244873047\n",
            "Inference Time: 0.21170401573181152\n",
            "Inference Time: 0.22327566146850586\n",
            "Inference Time: 0.22502851486206055\n",
            "Inference Time: 0.18955349922180176\n",
            "Inference Time: 0.24249720573425293\n",
            "Inference Time: 0.414031982421875\n",
            "Inference Time: 0.32413339614868164\n",
            "Inference Time: 0.23565196990966797\n",
            "Inference Time: 0.2653467655181885\n",
            "Inference Time: 0.26585841178894043\n",
            "Inference Time: 0.1883997917175293\n",
            "Inference Time: 0.27200818061828613\n",
            "Inference Time: 0.28510141372680664\n",
            "Inference Time: 0.22161078453063965\n",
            "Inference Time: 0.26461005210876465\n",
            "Inference Time: 0.22049760818481445\n",
            "Inference Time: 0.22205305099487305\n",
            "Inference Time: 0.29650044441223145\n",
            "Inference Time: 0.3051931858062744\n",
            "Inference Time: 0.2227315902709961\n",
            "Inference Time: 0.1909031867980957\n",
            "Inference Time: 0.22815370559692383\n",
            "Inference Time: 0.20768523216247559\n",
            "Inference Time: 0.33403992652893066\n",
            "Inference Time: 0.19343018531799316\n",
            "Inference Time: 0.12165522575378418\n",
            "Inference Time: 0.11645293235778809\n",
            "Inference Time: 0.12185883522033691\n",
            "Inference Time: 0.11550617218017578\n",
            "Inference Time: 0.11743855476379395\n",
            "Inference Time: 0.11652135848999023\n",
            "Inference Time: 0.11856317520141602\n",
            "Inference Time: 0.11227965354919434\n",
            "Inference Time: 0.1308753490447998\n",
            "Inference Time: 0.12523198127746582\n",
            "Inference Time: 0.12015891075134277\n",
            "Inference Time: 0.11114311218261719\n",
            "Inference Time: 0.11558699607849121\n",
            "Inference Time: 0.11795830726623535\n",
            "Inference Time: 0.1153714656829834\n",
            "Inference Time: 0.11926841735839844\n",
            "Inference Time: 0.13272476196289062\n",
            "Inference Time: 0.11574244499206543\n",
            "Inference Time: 0.11844730377197266\n",
            "Inference Time: 0.1260380744934082\n",
            "Inference Time: 0.12456822395324707\n",
            "Inference Time: 0.11069250106811523\n",
            "Inference Time: 0.12431836128234863\n",
            "Inference Time: 0.12208676338195801\n",
            "Inference Time: 0.12780332565307617\n",
            "Inference Time: 0.11662411689758301\n",
            "Inference Time: 0.11832141876220703\n",
            "Inference Time: 0.11319422721862793\n",
            "Inference Time: 0.12271761894226074\n",
            "Inference Time: 0.12174415588378906\n",
            "Inference Time: 0.12530946731567383\n",
            "Inference Time: 0.12146520614624023\n",
            "Inference Time: 0.12705445289611816\n",
            "Inference Time: 0.12912797927856445\n",
            "Inference Time: 0.11615633964538574\n",
            "Inference Time: 0.11845135688781738\n",
            "Inference Time: 0.12094640731811523\n",
            "Inference Time: 0.11583566665649414\n",
            "Inference Time: 0.11930155754089355\n",
            "Inference Time: 0.11961102485656738\n",
            "Inference Time: 0.11589431762695312\n",
            "Inference Time: 0.12756848335266113\n",
            "Inference Time: 0.11533904075622559\n",
            "Inference Time: 0.11947035789489746\n",
            "Inference Time: 0.12218308448791504\n",
            "Inference Time: 0.11089038848876953\n",
            "Inference Time: 0.12097883224487305\n",
            "Inference Time: 0.12406253814697266\n",
            "Inference Time: 0.1218879222869873\n",
            "Inference Time: 0.13618922233581543\n",
            "Inference Time: 0.1199800968170166\n",
            "Inference Time: 0.1111898422241211\n",
            "Inference Time: 0.11547303199768066\n",
            "Inference Time: 0.11990666389465332\n",
            "Inference Time: 0.11852145195007324\n",
            "Inference Time: 0.11108613014221191\n",
            "Inference Time: 0.1136472225189209\n",
            "Inference Time: 0.11125421524047852\n",
            "Inference Time: 0.13982152938842773\n",
            "Inference Time: 0.12557697296142578\n",
            "Inference Time: 0.11822319030761719\n",
            "Inference Time: 0.11922430992126465\n",
            "Inference Time: 0.11500906944274902\n",
            "Inference Time: 0.1163175106048584\n",
            "Inference Time: 0.14024782180786133\n",
            "Inference Time: 0.11861753463745117\n",
            "Inference Time: 0.12175822257995605\n",
            "Inference Time: 0.11719179153442383\n",
            "Inference Time: 0.11690378189086914\n",
            "Inference Time: 0.12161755561828613\n",
            "Inference Time: 0.12266826629638672\n",
            "Inference Time: 0.11697006225585938\n",
            "Inference Time: 0.12260198593139648\n",
            "Inference Time: 0.11905837059020996\n",
            "Inference Time: 0.11544060707092285\n",
            "Inference Time: 0.12409830093383789\n",
            "Inference Time: 0.12095832824707031\n",
            "Inference Time: 0.10976505279541016\n",
            "Inference Time: 0.1179194450378418\n",
            "Inference Time: 0.12913179397583008\n",
            "Inference Time: 0.12371635437011719\n",
            "Inference Time: 0.1153419017791748\n",
            "Inference Time: 0.11555218696594238\n",
            "Inference Time: 0.12578463554382324\n",
            "Inference Time: 0.11380863189697266\n",
            "Inference Time: 0.1132514476776123\n",
            "Inference Time: 0.12125587463378906\n",
            "Inference Time: 0.11625885963439941\n",
            "Inference Time: 0.1220545768737793\n",
            "Inference Time: 0.12229251861572266\n",
            "Inference Time: 0.12636923789978027\n",
            "Inference Time: 0.10797333717346191\n",
            "Inference Time: 0.12159895896911621\n",
            "Inference Time: 0.37975311279296875\n",
            "Inference Time: 0.4344017505645752\n",
            "Inference Time: 0.2645425796508789\n",
            "Inference Time: 0.1202385425567627\n",
            "Inference Time: 0.12044239044189453\n",
            "Inference Time: 0.11497092247009277\n",
            "Inference Time: 0.12761545181274414\n",
            "Inference Time: 0.11788821220397949\n",
            "Inference Time: 0.11770200729370117\n",
            "Inference Time: 0.11742377281188965\n",
            "Inference Time: 0.12313342094421387\n",
            "Inference Time: 0.10995721817016602\n",
            "Inference Time: 0.1275193691253662\n",
            "Inference Time: 0.11659002304077148\n",
            "Inference Time: 0.11843347549438477\n",
            "Inference Time: 0.11051011085510254\n",
            "Inference Time: 0.12307500839233398\n",
            "Inference Time: 0.11599540710449219\n",
            "Inference Time: 0.14080572128295898\n",
            "Inference Time: 0.11534714698791504\n",
            "Inference Time: 0.11409640312194824\n",
            "Inference Time: 0.11294865608215332\n",
            "Inference Time: 0.12245368957519531\n",
            "Inference Time: 0.11092090606689453\n",
            "Inference Time: 0.1261601448059082\n",
            "Inference Time: 0.11129450798034668\n",
            "Inference Time: 0.12871932983398438\n",
            "Inference Time: 0.12537884712219238\n",
            "Inference Time: 0.11941409111022949\n",
            "Inference Time: 0.1226205825805664\n",
            "Inference Time: 0.1224675178527832\n",
            "Inference Time: 0.11894822120666504\n",
            "Inference Time: 0.11741399765014648\n",
            "Inference Time: 0.11233806610107422\n",
            "Inference Time: 0.12023377418518066\n",
            "Inference Time: 0.1250603199005127\n",
            "Inference Time: 0.13046574592590332\n",
            "Inference Time: 0.12195420265197754\n",
            "Inference Time: 0.11870956420898438\n",
            "Inference Time: 0.1173868179321289\n",
            "Inference Time: 0.11594867706298828\n",
            "Inference Time: 0.11507439613342285\n",
            "Inference Time: 0.12138032913208008\n",
            "Inference Time: 0.11052465438842773\n",
            "Inference Time: 0.13357067108154297\n",
            "Inference Time: 0.11269760131835938\n",
            "Inference Time: 0.12358593940734863\n",
            "Inference Time: 0.11611628532409668\n",
            "Inference Time: 0.11945462226867676\n",
            "Inference Time: 0.11701416969299316\n",
            "Inference Time: 0.11522078514099121\n",
            "Inference Time: 0.11091327667236328\n",
            "Inference Time: 0.13373351097106934\n",
            "Inference Time: 0.11099815368652344\n",
            "Inference Time: 0.12099456787109375\n",
            "Inference Time: 0.11049294471740723\n",
            "Inference Time: 0.12436342239379883\n",
            "Inference Time: 0.11450338363647461\n",
            "Inference Time: 0.11648941040039062\n",
            "Inference Time: 0.11595559120178223\n",
            "Inference Time: 0.11780714988708496\n",
            "Inference Time: 0.11783528327941895\n",
            "Inference Time: 0.12005996704101562\n",
            "Inference Time: 0.11294746398925781\n",
            "Inference Time: 0.12399744987487793\n",
            "Inference Time: 0.11386823654174805\n",
            "Inference Time: 0.12564921379089355\n",
            "Inference Time: 0.11810612678527832\n",
            "Inference Time: 0.11777257919311523\n",
            "Inference Time: 0.12706565856933594\n",
            "Inference Time: 0.11733794212341309\n",
            "Inference Time: 0.11514925956726074\n",
            "Inference Time: 0.12138915061950684\n",
            "Inference Time: 0.11483573913574219\n",
            "Inference Time: 0.11736154556274414\n",
            "Inference Time: 0.11029624938964844\n",
            "Inference Time: 0.12205886840820312\n",
            "Inference Time: 0.11226749420166016\n",
            "Inference Time: 0.1221919059753418\n",
            "Inference Time: 0.1167292594909668\n",
            "Inference Time: 0.11940455436706543\n",
            "Inference Time: 0.11101484298706055\n",
            "Inference Time: 0.1279449462890625\n",
            "Inference Time: 0.11091375350952148\n",
            "Inference Time: 0.11419510841369629\n",
            "Inference Time: 0.11415362358093262\n",
            "Inference Time: 0.13969111442565918\n",
            "Inference Time: 0.1175999641418457\n",
            "Inference Time: 0.11931848526000977\n",
            "Inference Time: 0.11404180526733398\n",
            "Inference Time: 0.12307310104370117\n",
            "Inference Time: 0.11602163314819336\n",
            "Inference Time: 0.11487579345703125\n",
            "Inference Time: 0.11604523658752441\n",
            "Inference Time: 0.11220431327819824\n",
            "Inference Time: 0.11966705322265625\n",
            "Inference Time: 0.1288285255432129\n",
            "Inference Time: 0.10869050025939941\n",
            "Inference Time: 0.12542366981506348\n",
            "Inference Time: 0.11415481567382812\n",
            "Inference Time: 0.1224679946899414\n",
            "Inference Time: 0.1135411262512207\n",
            "Inference Time: 0.11556816101074219\n",
            "Inference Time: 0.12245059013366699\n",
            "Inference Time: 0.1298215389251709\n",
            "Inference Time: 0.12431550025939941\n",
            "Inference Time: 0.12305855751037598\n",
            "Inference Time: 0.11125802993774414\n",
            "Inference Time: 0.1182258129119873\n",
            "Inference Time: 0.11186575889587402\n",
            "Inference Time: 0.11903810501098633\n",
            "Inference Time: 0.11756491661071777\n",
            "Inference Time: 0.13895249366760254\n",
            "Inference Time: 0.11514425277709961\n",
            "Inference Time: 0.11536455154418945\n",
            "Inference Time: 0.11297440528869629\n",
            "Inference Time: 0.1266160011291504\n",
            "Inference Time: 0.11036276817321777\n",
            "Inference Time: 0.11871695518493652\n",
            "Inference Time: 0.11619758605957031\n",
            "Inference Time: 0.12536287307739258\n",
            "Inference Time: 0.1139380931854248\n",
            "Inference Time: 0.1218729019165039\n",
            "Inference Time: 0.11245584487915039\n",
            "Inference Time: 0.12372350692749023\n",
            "Inference Time: 0.11717605590820312\n",
            "Inference Time: 0.13349461555480957\n",
            "Inference Time: 0.1240384578704834\n",
            "Inference Time: 0.12466096878051758\n",
            "Inference Time: 0.12037014961242676\n",
            "Inference Time: 0.11750483512878418\n",
            "Inference Time: 0.11722755432128906\n",
            "Inference Time: 0.12077045440673828\n",
            "Inference Time: 0.11020278930664062\n",
            "Inference Time: 0.12149524688720703\n",
            "Inference Time: 0.10809874534606934\n",
            "Inference Time: 0.14260149002075195\n",
            "Inference Time: 0.12125229835510254\n",
            "Inference Time: 0.11317896842956543\n",
            "Inference Time: 0.11508297920227051\n",
            "Inference Time: 0.11252021789550781\n",
            "Inference Time: 0.10882258415222168\n",
            "Inference Time: 0.11677169799804688\n",
            "Inference Time: 0.11080145835876465\n",
            "Inference Time: 0.11939144134521484\n",
            "Inference Time: 0.10869169235229492\n",
            "Inference Time: 0.13655900955200195\n",
            "Inference Time: 0.11267232894897461\n",
            "Inference Time: 0.11428284645080566\n",
            "Inference Time: 0.11525297164916992\n",
            "Inference Time: 0.1179654598236084\n",
            "Inference Time: 0.12041020393371582\n",
            "Inference Time: 0.11431002616882324\n",
            "Inference Time: 0.11236143112182617\n",
            "Inference Time: 0.13555431365966797\n",
            "Inference Time: 0.11356329917907715\n",
            "Inference Time: 0.13123512268066406\n",
            "Inference Time: 0.11843657493591309\n",
            "Inference Time: 0.11377358436584473\n",
            "Inference Time: 0.11769413948059082\n",
            "Inference Time: 0.11759042739868164\n",
            "Inference Time: 0.11565899848937988\n",
            "Inference Time: 0.11585068702697754\n",
            "Inference Time: 0.1278069019317627\n",
            "Inference Time: 0.12331938743591309\n",
            "Inference Time: 0.11249184608459473\n",
            "Inference Time: 0.13909626007080078\n",
            "Inference Time: 0.11681151390075684\n",
            "Inference Time: 0.12323164939880371\n",
            "Inference Time: 0.11900019645690918\n",
            "Inference Time: 0.11423873901367188\n",
            "Inference Time: 0.13060617446899414\n",
            "Inference Time: 0.12084603309631348\n",
            "Inference Time: 0.11410951614379883\n",
            "Inference Time: 0.1154184341430664\n",
            "Inference Time: 0.11343812942504883\n",
            "Inference Time: 0.1378312110900879\n",
            "Inference Time: 0.11442089080810547\n",
            "Inference Time: 0.12108969688415527\n",
            "Inference Time: 0.1228940486907959\n",
            "Inference Time: 0.12438607215881348\n",
            "Inference Time: 0.10736966133117676\n",
            "Inference Time: 0.11635375022888184\n",
            "Inference Time: 0.11937808990478516\n",
            "Inference Time: 0.1193540096282959\n",
            "Inference Time: 0.1097419261932373\n",
            "Inference Time: 0.13326644897460938\n",
            "Inference Time: 0.11487960815429688\n",
            "Inference Time: 0.1433696746826172\n",
            "Inference Time: 0.12173604965209961\n",
            "Inference Time: 0.11834025382995605\n",
            "Inference Time: 0.11585044860839844\n",
            "Inference Time: 0.12430667877197266\n",
            "Inference Time: 0.11924505233764648\n",
            "Inference Time: 0.12984299659729004\n",
            "Inference Time: 0.11019134521484375\n",
            "Inference Time: 0.13589715957641602\n",
            "Inference Time: 0.11490559577941895\n",
            "Inference Time: 0.11584925651550293\n",
            "Inference Time: 0.11560893058776855\n",
            "Inference Time: 0.12001299858093262\n",
            "Inference Time: 0.11852741241455078\n",
            "Inference Time: 0.11994576454162598\n",
            "Inference Time: 0.11103630065917969\n",
            "Inference Time: 0.13580846786499023\n",
            "Inference Time: 0.11064934730529785\n",
            "Inference Time: 0.12424588203430176\n",
            "Inference Time: 0.11884307861328125\n",
            "Inference Time: 0.11524581909179688\n",
            "Inference Time: 0.11482501029968262\n",
            "Inference Time: 0.1262340545654297\n",
            "Inference Time: 0.11717057228088379\n",
            "Inference Time: 0.13296890258789062\n",
            "Inference Time: 0.13617777824401855\n",
            "Inference Time: 0.12316632270812988\n",
            "Inference Time: 0.11197829246520996\n",
            "Inference Time: 0.1261734962463379\n",
            "Inference Time: 0.11506962776184082\n",
            "Inference Time: 0.11781978607177734\n",
            "Inference Time: 0.11371636390686035\n",
            "Inference Time: 0.11810970306396484\n",
            "Inference Time: 0.12184286117553711\n",
            "Inference Time: 0.1171560287475586\n",
            "Inference Time: 0.10958981513977051\n",
            "Inference Time: 0.12079405784606934\n",
            "Inference Time: 0.11550712585449219\n",
            "Inference Time: 0.12875628471374512\n",
            "Inference Time: 0.11945366859436035\n",
            "Inference Time: 0.11433815956115723\n",
            "Inference Time: 0.11447668075561523\n",
            "Inference Time: 0.1325974464416504\n",
            "Inference Time: 0.10865306854248047\n",
            "Inference Time: 0.11978912353515625\n",
            "Inference Time: 0.11475825309753418\n",
            "Inference Time: 0.11612510681152344\n",
            "Inference Time: 0.11794257164001465\n",
            "Inference Time: 0.12644338607788086\n",
            "Inference Time: 0.11772704124450684\n",
            "Inference Time: 0.12864065170288086\n",
            "Inference Time: 0.11405730247497559\n",
            "Inference Time: 0.11522769927978516\n",
            "Inference Time: 0.1118919849395752\n",
            "Inference Time: 0.1224815845489502\n",
            "Inference Time: 0.1235799789428711\n",
            "Inference Time: 0.11968183517456055\n",
            "Inference Time: 0.11575746536254883\n",
            "Inference Time: 0.13449645042419434\n",
            "Inference Time: 0.12717556953430176\n",
            "Inference Time: 0.12508893013000488\n",
            "Inference Time: 0.12391448020935059\n",
            "Inference Time: 0.1191248893737793\n",
            "Inference Time: 0.11807608604431152\n",
            "Inference Time: 0.1139669418334961\n",
            "Inference Time: 0.11274600028991699\n",
            "Inference Time: 0.12127828598022461\n",
            "Inference Time: 0.12138676643371582\n",
            "Inference Time: 0.13852810859680176\n",
            "Inference Time: 0.11694765090942383\n",
            "Inference Time: 0.11688542366027832\n",
            "Inference Time: 0.11957788467407227\n",
            "Inference Time: 0.1235194206237793\n",
            "Inference Time: 0.11289024353027344\n",
            "Inference Time: 0.11395049095153809\n",
            "Inference Time: 0.11165046691894531\n",
            "Inference Time: 0.11569619178771973\n",
            "Inference Time: 0.11593866348266602\n",
            "Inference Time: 0.1362321376800537\n",
            "Inference Time: 0.11732649803161621\n",
            "Inference Time: 0.11587309837341309\n",
            "Inference Time: 0.11534500122070312\n",
            "Inference Time: 0.11624431610107422\n",
            "Inference Time: 0.11825776100158691\n",
            "Inference Time: 0.12860655784606934\n",
            "Inference Time: 0.12421059608459473\n",
            "Inference Time: 0.12185502052307129\n",
            "Inference Time: 0.12097835540771484\n",
            "Inference Time: 0.13815927505493164\n",
            "Inference Time: 0.11831355094909668\n",
            "Inference Time: 0.12421751022338867\n",
            "Inference Time: 0.11395502090454102\n",
            "Inference Time: 0.12928080558776855\n",
            "Inference Time: 0.1132192611694336\n",
            "Inference Time: 0.11653280258178711\n",
            "Inference Time: 0.1126406192779541\n",
            "Inference Time: 0.12331175804138184\n",
            "Inference Time: 0.12616324424743652\n",
            "Inference Time: 0.1329360008239746\n",
            "Inference Time: 0.11675548553466797\n",
            "Inference Time: 0.1266467571258545\n",
            "Inference Time: 0.1148080825805664\n",
            "Inference Time: 0.12414407730102539\n",
            "Inference Time: 0.11507868766784668\n",
            "Inference Time: 0.11829352378845215\n",
            "Inference Time: 0.11848974227905273\n",
            "Inference Time: 0.1215200424194336\n",
            "Inference Time: 0.11673593521118164\n",
            "Inference Time: 0.12675094604492188\n",
            "Inference Time: 0.12285351753234863\n",
            "Inference Time: 0.12145543098449707\n",
            "Inference Time: 0.13721871376037598\n",
            "Inference Time: 0.12495136260986328\n",
            "Inference Time: 0.11668801307678223\n",
            "Inference Time: 0.12416625022888184\n",
            "Inference Time: 0.11555624008178711\n",
            "Inference Time: 0.11326909065246582\n",
            "Inference Time: 0.12699556350708008\n",
            "Inference Time: 0.12652087211608887\n",
            "Inference Time: 0.12298083305358887\n",
            "Inference Time: 0.1152334213256836\n",
            "Inference Time: 0.1143484115600586\n",
            "Inference Time: 0.12321949005126953\n",
            "Inference Time: 0.12287497520446777\n",
            "Inference Time: 0.12062954902648926\n",
            "Inference Time: 0.12123584747314453\n",
            "Inference Time: 0.11672806739807129\n",
            "Inference Time: 0.11358785629272461\n",
            "Inference Time: 0.13332700729370117\n",
            "Inference Time: 0.11182093620300293\n",
            "Inference Time: 0.1237947940826416\n",
            "Inference Time: 0.12082695960998535\n",
            "Inference Time: 0.12303757667541504\n",
            "Inference Time: 0.1120150089263916\n",
            "Inference Time: 0.1304624080657959\n",
            "Inference Time: 0.12209224700927734\n",
            "Inference Time: 0.12196922302246094\n",
            "Inference Time: 0.11612248420715332\n",
            "Inference Time: 0.12337708473205566\n",
            "Inference Time: 0.11533331871032715\n",
            "Inference Time: 0.12159180641174316\n",
            "Inference Time: 0.1097869873046875\n",
            "Inference Time: 0.1335127353668213\n",
            "Inference Time: 0.11879253387451172\n",
            "Inference Time: 0.11494779586791992\n",
            "Inference Time: 0.11436629295349121\n",
            "Inference Time: 0.12308287620544434\n",
            "Inference Time: 0.11601495742797852\n",
            "Inference Time: 0.1306154727935791\n",
            "Inference Time: 0.11815690994262695\n",
            "Inference Time: 0.11533522605895996\n",
            "Inference Time: 0.12513995170593262\n",
            "Inference Time: 0.11738967895507812\n",
            "Inference Time: 0.1171562671661377\n",
            "Inference Time: 0.11891865730285645\n",
            "Inference Time: 0.1161184310913086\n",
            "Inference Time: 0.11580276489257812\n",
            "Inference Time: 0.11318492889404297\n",
            "Inference Time: 0.12247610092163086\n",
            "Inference Time: 0.1270291805267334\n",
            "Inference Time: 0.12119722366333008\n",
            "Inference Time: 0.12459325790405273\n",
            "Inference Time: 0.12154793739318848\n",
            "Inference Time: 0.1148982048034668\n",
            "Inference Time: 0.11866021156311035\n",
            "Inference Time: 0.11591100692749023\n",
            "Inference Time: 0.11692285537719727\n",
            "Inference Time: 0.11830759048461914\n",
            "Inference Time: 0.14400219917297363\n",
            "Inference Time: 0.11298131942749023\n",
            "Inference Time: 0.12282824516296387\n",
            "Inference Time: 0.11165666580200195\n",
            "Inference Time: 0.11885738372802734\n",
            "Inference Time: 0.11250185966491699\n",
            "Inference Time: 0.11107993125915527\n",
            "Inference Time: 0.11574053764343262\n",
            "Inference Time: 0.12760591506958008\n",
            "Inference Time: 0.11328601837158203\n",
            "Inference Time: 0.12677288055419922\n",
            "Inference Time: 0.11715078353881836\n",
            "Inference Time: 0.12499713897705078\n",
            "Inference Time: 0.11921834945678711\n",
            "Inference Time: 0.11710000038146973\n",
            "Inference Time: 0.12064576148986816\n",
            "Inference Time: 0.12195706367492676\n",
            "Inference Time: 0.11605548858642578\n",
            "Inference Time: 0.11733722686767578\n",
            "Inference Time: 0.10942363739013672\n",
            "Inference Time: 0.12807297706604004\n",
            "Inference Time: 0.10909008979797363\n",
            "Inference Time: 0.11336398124694824\n",
            "Inference Time: 0.10821080207824707\n",
            "Inference Time: 0.11424660682678223\n",
            "Inference Time: 0.13177084922790527\n",
            "Inference Time: 0.1108863353729248\n",
            "Inference Time: 0.1066133975982666\n",
            "Inference Time: 0.11480975151062012\n",
            "Inference Time: 0.11121821403503418\n",
            "Inference Time: 0.1277167797088623\n",
            "Inference Time: 0.11066365242004395\n",
            "Inference Time: 0.11445164680480957\n",
            "Inference Time: 0.11728239059448242\n",
            "Inference Time: 0.13323736190795898\n",
            "Inference Time: 0.1196143627166748\n",
            "Inference Time: 0.11479783058166504\n",
            "Inference Time: 0.10918211936950684\n",
            "Inference Time: 0.12656927108764648\n",
            "Inference Time: 0.11850714683532715\n",
            "Inference Time: 0.1362009048461914\n",
            "Inference Time: 0.11182308197021484\n",
            "Inference Time: 0.13433361053466797\n",
            "Inference Time: 0.11060953140258789\n",
            "Inference Time: 0.11501097679138184\n",
            "Inference Time: 0.11731624603271484\n",
            "Inference Time: 0.11725091934204102\n",
            "Inference Time: 0.11426568031311035\n",
            "Inference Time: 0.11036014556884766\n",
            "Inference Time: 0.11152815818786621\n",
            "Inference Time: 0.1260688304901123\n",
            "Inference Time: 0.12190485000610352\n",
            "Inference Time: 0.11631488800048828\n",
            "Inference Time: 0.1067814826965332\n",
            "Inference Time: 0.11400651931762695\n",
            "Inference Time: 0.12006616592407227\n",
            "Inference Time: 0.11568546295166016\n",
            "Inference Time: 0.10947179794311523\n",
            "Inference Time: 0.12047958374023438\n",
            "Inference Time: 0.10742330551147461\n",
            "Inference Time: 0.13801980018615723\n",
            "Inference Time: 0.11077737808227539\n",
            "Inference Time: 0.11658978462219238\n",
            "Inference Time: 0.12020730972290039\n",
            "Inference Time: 0.12120270729064941\n",
            "Inference Time: 0.1119084358215332\n",
            "Inference Time: 0.11702513694763184\n",
            "Inference Time: 0.10816216468811035\n",
            "Inference Time: 0.13617515563964844\n",
            "Inference Time: 0.10823416709899902\n",
            "Inference Time: 0.12859654426574707\n",
            "Inference Time: 0.11052393913269043\n",
            "Inference Time: 0.11305522918701172\n",
            "Inference Time: 0.12372088432312012\n",
            "Inference Time: 0.11963224411010742\n",
            "Inference Time: 0.11347532272338867\n",
            "Inference Time: 0.11565065383911133\n",
            "Inference Time: 0.11751246452331543\n",
            "Inference Time: 0.11925840377807617\n",
            "Inference Time: 0.11052060127258301\n",
            "Inference Time: 0.1333167552947998\n",
            "Inference Time: 0.11325764656066895\n",
            "Inference Time: 0.11974334716796875\n",
            "Inference Time: 0.1208341121673584\n",
            "Inference Time: 0.11246013641357422\n",
            "Inference Time: 0.12734246253967285\n",
            "Inference Time: 0.11982417106628418\n",
            "Inference Time: 0.11157536506652832\n",
            "Inference Time: 0.11502408981323242\n",
            "Inference Time: 0.11503720283508301\n",
            "Inference Time: 0.13084173202514648\n",
            "Inference Time: 0.11117053031921387\n",
            "Inference Time: 0.11565279960632324\n",
            "Inference Time: 0.12011289596557617\n",
            "Inference Time: 0.12250900268554688\n",
            "Inference Time: 0.11804866790771484\n",
            "Inference Time: 0.11500358581542969\n",
            "Inference Time: 0.11304998397827148\n",
            "Inference Time: 0.11920428276062012\n",
            "Inference Time: 0.11652207374572754\n",
            "Inference Time: 0.14022421836853027\n",
            "Inference Time: 0.11040377616882324\n",
            "Inference Time: 0.13461899757385254\n",
            "Inference Time: 0.1334819793701172\n",
            "Inference Time: 0.11883139610290527\n",
            "Inference Time: 0.1159360408782959\n",
            "Inference Time: 0.1203606128692627\n",
            "Inference Time: 0.10809540748596191\n",
            "Inference Time: 0.1240999698638916\n",
            "Inference Time: 0.10703253746032715\n",
            "Inference Time: 0.12879085540771484\n",
            "Inference Time: 0.12372565269470215\n",
            "Inference Time: 0.11706042289733887\n",
            "Inference Time: 0.11277222633361816\n",
            "Inference Time: 0.11165332794189453\n",
            "Inference Time: 0.10709953308105469\n",
            "Inference Time: 0.12070059776306152\n",
            "Inference Time: 0.11678504943847656\n",
            "Inference Time: 0.12152528762817383\n",
            "Inference Time: 0.11978507041931152\n",
            "Inference Time: 0.12278437614440918\n",
            "Inference Time: 0.11221623420715332\n",
            "Inference Time: 0.11236715316772461\n",
            "Inference Time: 0.11872100830078125\n",
            "Inference Time: 0.12042760848999023\n",
            "Inference Time: 0.11653280258178711\n",
            "Inference Time: 0.11696839332580566\n",
            "Inference Time: 0.112701416015625\n",
            "Inference Time: 0.12408304214477539\n",
            "Inference Time: 0.10730314254760742\n",
            "Inference Time: 0.13016390800476074\n",
            "Inference Time: 0.11305975914001465\n",
            "Inference Time: 0.11178755760192871\n",
            "Inference Time: 0.12062835693359375\n",
            "Inference Time: 0.11251091957092285\n",
            "Inference Time: 0.11084103584289551\n",
            "Inference Time: 0.14010190963745117\n",
            "Inference Time: 0.11924362182617188\n",
            "Inference Time: 0.12827467918395996\n",
            "Inference Time: 0.11089444160461426\n",
            "Inference Time: 0.12898635864257812\n",
            "Inference Time: 0.11973714828491211\n",
            "Inference Time: 0.11486649513244629\n",
            "Inference Time: 0.12643957138061523\n",
            "Inference Time: 0.11592841148376465\n",
            "Inference Time: 0.12733149528503418\n",
            "Inference Time: 0.11684846878051758\n",
            "Inference Time: 0.10988545417785645\n",
            "Inference Time: 0.11927175521850586\n",
            "Inference Time: 0.11225605010986328\n",
            "Inference Time: 0.1303722858428955\n",
            "Inference Time: 0.11148619651794434\n",
            "Inference Time: 0.11895370483398438\n",
            "Inference Time: 0.1333777904510498\n",
            "Inference Time: 0.11809849739074707\n",
            "Inference Time: 0.11608529090881348\n",
            "Inference Time: 0.11908769607543945\n",
            "Inference Time: 0.11269283294677734\n",
            "Inference Time: 0.12651705741882324\n",
            "Inference Time: 0.11108160018920898\n",
            "Inference Time: 0.12569284439086914\n",
            "Inference Time: 50.56500792503357\n",
            "Inference Time: 0.11500692367553711\n",
            "Inference Time: 0.11794614791870117\n",
            "Inference Time: 0.11127257347106934\n",
            "Inference Time: 0.12154531478881836\n",
            "Inference Time: 0.1227109432220459\n",
            "Inference Time: 0.12383580207824707\n",
            "Inference Time: 0.11763787269592285\n",
            "Inference Time: 0.11772966384887695\n",
            "Inference Time: 0.12470722198486328\n",
            "Inference Time: 0.12333035469055176\n",
            "Inference Time: 0.11375761032104492\n",
            "Inference Time: 0.11949825286865234\n",
            "Inference Time: 0.12497878074645996\n",
            "Inference Time: 0.11906218528747559\n",
            "Inference Time: 0.11408209800720215\n",
            "Inference Time: 0.12781929969787598\n",
            "Inference Time: 0.11944150924682617\n",
            "Inference Time: 0.12343287467956543\n",
            "Inference Time: 0.14632534980773926\n",
            "Inference Time: 0.1292564868927002\n",
            "Inference Time: 0.13988399505615234\n",
            "Inference Time: 0.12105250358581543\n",
            "Inference Time: 0.1150515079498291\n",
            "Inference Time: 0.11556363105773926\n",
            "Inference Time: 0.1146535873413086\n",
            "Inference Time: 0.11701655387878418\n",
            "Inference Time: 0.11256241798400879\n",
            "Inference Time: 0.12105584144592285\n",
            "Inference Time: 0.14478564262390137\n",
            "Inference Time: 0.11555218696594238\n",
            "Inference Time: 0.11300158500671387\n",
            "Inference Time: 0.12050056457519531\n",
            "Inference Time: 0.11279726028442383\n",
            "Inference Time: 0.1136617660522461\n",
            "Inference Time: 0.11749148368835449\n",
            "Inference Time: 0.1147451400756836\n",
            "Inference Time: 0.11412525177001953\n",
            "Inference Time: 0.13096857070922852\n",
            "Inference Time: 0.12183117866516113\n",
            "Inference Time: 0.11861634254455566\n",
            "Inference Time: 0.11061739921569824\n",
            "Inference Time: 0.11491823196411133\n",
            "Inference Time: 0.12814760208129883\n",
            "Inference Time: 0.11540508270263672\n",
            "Inference Time: 0.11334681510925293\n",
            "Inference Time: 0.1266345977783203\n",
            "Inference Time: 0.11589169502258301\n",
            "Inference Time: 0.11759138107299805\n",
            "Inference Time: 0.12507200241088867\n",
            "Inference Time: 0.12399005889892578\n",
            "Inference Time: 0.11164140701293945\n",
            "Inference Time: 0.11588025093078613\n",
            "Inference Time: 0.11772346496582031\n",
            "Inference Time: 0.11873269081115723\n",
            "Inference Time: 0.12796258926391602\n",
            "Inference Time: 0.12163329124450684\n",
            "Inference Time: 0.11856937408447266\n",
            "Inference Time: 0.12883806228637695\n",
            "Inference Time: 0.12636828422546387\n",
            "Inference Time: 0.12188839912414551\n",
            "Inference Time: 0.11263847351074219\n",
            "Inference Time: 0.11766338348388672\n",
            "Inference Time: 0.12344145774841309\n",
            "Inference Time: 0.11810731887817383\n",
            "Inference Time: 0.11789512634277344\n",
            "Inference Time: 0.11506223678588867\n",
            "Inference Time: 0.1172337532043457\n",
            "Inference Time: 0.1196141242980957\n",
            "Inference Time: 0.12176227569580078\n",
            "Inference Time: 0.11902785301208496\n",
            "Inference Time: 0.12083721160888672\n",
            "Inference Time: 0.11018180847167969\n",
            "Inference Time: 0.11750078201293945\n",
            "Inference Time: 0.11697006225585938\n",
            "Inference Time: 0.11866068840026855\n",
            "Inference Time: 0.1202692985534668\n",
            "Inference Time: 0.10895252227783203\n",
            "Inference Time: 0.11383843421936035\n",
            "Inference Time: 0.12682843208312988\n",
            "Inference Time: 0.12677836418151855\n",
            "Inference Time: 0.11552548408508301\n",
            "Inference Time: 0.12168335914611816\n",
            "Inference Time: 0.11085820198059082\n",
            "Inference Time: 0.1226339340209961\n",
            "Inference Time: 0.11805438995361328\n",
            "Inference Time: 0.1201941967010498\n",
            "Inference Time: 0.11681008338928223\n",
            "Inference Time: 0.12555599212646484\n",
            "Inference Time: 0.139754056930542\n",
            "Inference Time: 0.11819744110107422\n",
            "Inference Time: 0.11475849151611328\n",
            "Inference Time: 0.11974287033081055\n",
            "Inference Time: 0.1136777400970459\n",
            "Inference Time: 0.11494159698486328\n",
            "Inference Time: 0.11320900917053223\n",
            "Inference Time: 0.12058329582214355\n",
            "Inference Time: 0.1184990406036377\n",
            "Inference Time: 0.11809301376342773\n",
            "Inference Time: 0.13042092323303223\n",
            "Inference Time: 0.12592172622680664\n",
            "Inference Time: 0.11847090721130371\n",
            "Inference Time: 0.1248314380645752\n",
            "Inference Time: 0.11561799049377441\n",
            "Inference Time: 0.12250161170959473\n",
            "Inference Time: 0.13328909873962402\n",
            "Inference Time: 0.12176656723022461\n",
            "Inference Time: 0.11482906341552734\n",
            "Inference Time: 0.12051653861999512\n",
            "Inference Time: 0.1226661205291748\n",
            "Inference Time: 0.11987686157226562\n",
            "Inference Time: 0.11688041687011719\n",
            "Inference Time: 0.12529706954956055\n",
            "Inference Time: 0.12701201438903809\n",
            "Inference Time: 0.11600136756896973\n",
            "Inference Time: 0.11943197250366211\n",
            "Inference Time: 0.11839771270751953\n",
            "Inference Time: 0.11699438095092773\n",
            "Inference Time: 0.11871194839477539\n",
            "Inference Time: 0.12558579444885254\n",
            "Inference Time: 0.1205747127532959\n",
            "Inference Time: 0.11577796936035156\n",
            "Inference Time: 0.12963438034057617\n",
            "Inference Time: 0.12583160400390625\n",
            "Inference Time: 0.12011599540710449\n",
            "Inference Time: 0.11660909652709961\n",
            "Inference Time: 0.11722302436828613\n",
            "Inference Time: 0.11363458633422852\n",
            "Inference Time: 0.11863207817077637\n",
            "Inference Time: 0.12259364128112793\n",
            "Inference Time: 0.12810111045837402\n",
            "Inference Time: 0.112823486328125\n",
            "Inference Time: 0.12166476249694824\n",
            "Inference Time: 0.11560273170471191\n",
            "Inference Time: 0.11637520790100098\n",
            "Inference Time: 0.11675620079040527\n",
            "Inference Time: 0.12006616592407227\n",
            "Inference Time: 0.11746001243591309\n",
            "Inference Time: 0.11995935440063477\n",
            "Inference Time: 0.13489437103271484\n",
            "Inference Time: 0.13103771209716797\n",
            "Inference Time: 0.11588025093078613\n",
            "Inference Time: 0.12987232208251953\n",
            "Inference Time: 0.12448358535766602\n",
            "Inference Time: 0.11776900291442871\n",
            "Inference Time: 0.11362004280090332\n",
            "Inference Time: 0.11680245399475098\n",
            "Inference Time: 0.11713910102844238\n",
            "Inference Time: 0.12269783020019531\n",
            "Inference Time: 0.12259745597839355\n",
            "Inference Time: 0.1198720932006836\n",
            "Inference Time: 0.1172795295715332\n",
            "Inference Time: 0.12752246856689453\n",
            "Inference Time: 0.1119992733001709\n",
            "Inference Time: 0.11626505851745605\n",
            "Inference Time: 0.12232422828674316\n",
            "Inference Time: 0.13040399551391602\n",
            "Inference Time: 0.11396574974060059\n",
            "Inference Time: 0.11474275588989258\n",
            "Inference Time: 0.12188124656677246\n",
            "Inference Time: 0.1196434497833252\n",
            "Inference Time: 0.10996484756469727\n",
            "Inference Time: 0.11638140678405762\n",
            "Inference Time: 0.11105895042419434\n",
            "Inference Time: 0.12361383438110352\n",
            "Inference Time: 0.11758828163146973\n",
            "Inference Time: 0.1207430362701416\n",
            "Inference Time: 0.11301374435424805\n",
            "Inference Time: 0.11603045463562012\n",
            "Inference Time: 0.12764668464660645\n",
            "Inference Time: 0.12146544456481934\n",
            "Inference Time: 0.1120002269744873\n",
            "Inference Time: 0.13691258430480957\n",
            "Inference Time: 0.11952996253967285\n",
            "Inference Time: 0.11694979667663574\n",
            "Inference Time: 0.11924338340759277\n",
            "Inference Time: 0.1279292106628418\n",
            "Inference Time: 0.12076425552368164\n",
            "Inference Time: 0.1241457462310791\n",
            "Inference Time: 0.12955570220947266\n",
            "Inference Time: 0.13715362548828125\n",
            "Inference Time: 0.12262487411499023\n",
            "Inference Time: 0.12264275550842285\n",
            "Inference Time: 0.1186530590057373\n",
            "Inference Time: 0.12370800971984863\n",
            "Inference Time: 0.1186068058013916\n",
            "Inference Time: 0.12233901023864746\n",
            "Inference Time: 0.11193323135375977\n",
            "Inference Time: 0.11754107475280762\n",
            "Inference Time: 0.1509418487548828\n",
            "Inference Time: 0.11815619468688965\n",
            "Inference Time: 0.11412882804870605\n",
            "Inference Time: 0.12329673767089844\n",
            "Inference Time: 0.11132574081420898\n",
            "Inference Time: 0.1212155818939209\n",
            "Inference Time: 0.11008000373840332\n",
            "Inference Time: 0.11887073516845703\n",
            "Inference Time: 0.1298673152923584\n",
            "Inference Time: 0.11483216285705566\n",
            "Inference Time: 0.13332748413085938\n",
            "Inference Time: 0.11992025375366211\n",
            "Inference Time: 0.12337493896484375\n",
            "Inference Time: 0.12221169471740723\n",
            "Inference Time: 0.1154019832611084\n",
            "Inference Time: 0.12496662139892578\n",
            "Inference Time: 0.13492083549499512\n",
            "Inference Time: 0.12012672424316406\n",
            "Inference Time: 0.11111307144165039\n",
            "Inference Time: 0.11910629272460938\n",
            "Inference Time: 0.1241910457611084\n",
            "Inference Time: 0.11832523345947266\n",
            "Inference Time: 0.11833524703979492\n",
            "Inference Time: 0.11883759498596191\n",
            "Inference Time: 0.11475729942321777\n",
            "Inference Time: 0.13526701927185059\n",
            "Inference Time: 0.11336016654968262\n",
            "Inference Time: 0.1210775375366211\n",
            "Inference Time: 0.11721014976501465\n",
            "Inference Time: 0.12532424926757812\n",
            "Inference Time: 0.13158464431762695\n",
            "Inference Time: 0.12263703346252441\n",
            "Inference Time: 0.13622164726257324\n",
            "Inference Time: 0.13792181015014648\n",
            "Inference Time: 0.1127328872680664\n",
            "Inference Time: 0.12323856353759766\n",
            "Inference Time: 0.11463499069213867\n",
            "Inference Time: 0.11747336387634277\n",
            "Inference Time: 0.1101233959197998\n",
            "Inference Time: 0.1248176097869873\n",
            "Inference Time: 0.13979744911193848\n",
            "Inference Time: 0.13211870193481445\n",
            "Inference Time: 0.11515641212463379\n",
            "Inference Time: 0.12533259391784668\n",
            "Inference Time: 0.11142301559448242\n",
            "Inference Time: 0.12028717994689941\n",
            "Inference Time: 0.11402225494384766\n",
            "Inference Time: 0.12186861038208008\n",
            "Inference Time: 0.11374616622924805\n",
            "Inference Time: 0.1391923427581787\n",
            "Inference Time: 0.1241464614868164\n",
            "Inference Time: 0.12051606178283691\n",
            "Inference Time: 0.11533451080322266\n",
            "Inference Time: 0.12089371681213379\n",
            "Inference Time: 0.11368703842163086\n",
            "Inference Time: 0.1268293857574463\n",
            "Inference Time: 0.11519551277160645\n",
            "Inference Time: 0.13035249710083008\n",
            "Inference Time: 0.11443519592285156\n",
            "Inference Time: 0.12031316757202148\n",
            "Inference Time: 0.12671494483947754\n",
            "Inference Time: 0.11385154724121094\n",
            "Inference Time: 0.11605596542358398\n",
            "Inference Time: 0.11821913719177246\n",
            "Inference Time: 0.11516618728637695\n",
            "Inference Time: 0.12222862243652344\n",
            "Inference Time: 0.12290000915527344\n",
            "Inference Time: 0.12487220764160156\n",
            "Inference Time: 0.11168479919433594\n",
            "Inference Time: 0.11843609809875488\n",
            "Inference Time: 0.1271054744720459\n",
            "Inference Time: 0.11681270599365234\n",
            "Inference Time: 0.12739944458007812\n",
            "Inference Time: 0.11487579345703125\n",
            "Inference Time: 0.12069463729858398\n",
            "Inference Time: 0.11986660957336426\n",
            "Inference Time: 0.13075542449951172\n",
            "Inference Time: 0.12882637977600098\n",
            "Inference Time: 0.11434698104858398\n",
            "Inference Time: 0.12897753715515137\n",
            "Inference Time: 0.12815022468566895\n",
            "Inference Time: 0.12306332588195801\n",
            "Inference Time: 0.12788772583007812\n",
            "Inference Time: 0.13344025611877441\n",
            "Inference Time: 0.12149786949157715\n",
            "Inference Time: 0.12399101257324219\n",
            "Inference Time: 0.11315011978149414\n",
            "Inference Time: 0.12329530715942383\n",
            "Inference Time: 0.11406636238098145\n",
            "Inference Time: 0.12395715713500977\n",
            "Inference Time: 0.12568449974060059\n",
            "Inference Time: 0.1268153190612793\n",
            "Inference Time: 0.12015867233276367\n",
            "Inference Time: 0.11903119087219238\n",
            "Inference Time: 0.11978650093078613\n",
            "Inference Time: 0.11925244331359863\n",
            "Inference Time: 0.11497354507446289\n",
            "Inference Time: 0.12290811538696289\n",
            "Inference Time: 0.11100101470947266\n",
            "Inference Time: 0.12861299514770508\n",
            "Inference Time: 0.12572693824768066\n",
            "Inference Time: 0.11994433403015137\n",
            "Inference Time: 0.1160135269165039\n",
            "Inference Time: 0.12222719192504883\n",
            "Inference Time: 0.11646890640258789\n",
            "Inference Time: 0.11688971519470215\n",
            "Inference Time: 0.1098330020904541\n",
            "Inference Time: 0.12345099449157715\n",
            "Inference Time: 0.12464118003845215\n",
            "Inference Time: 0.13189077377319336\n",
            "Inference Time: 0.12966084480285645\n",
            "Inference Time: 0.12084341049194336\n",
            "Inference Time: 0.1100149154663086\n",
            "Inference Time: 0.12410736083984375\n",
            "Inference Time: 0.1264655590057373\n",
            "Inference Time: 0.11464214324951172\n",
            "Inference Time: 0.12976527214050293\n",
            "Inference Time: 0.12148308753967285\n",
            "Inference Time: 0.11377620697021484\n",
            "Inference Time: 0.12024974822998047\n",
            "Inference Time: 0.13391947746276855\n",
            "Inference Time: 0.12392735481262207\n",
            "Inference Time: 0.11353588104248047\n",
            "Inference Time: 0.12096548080444336\n",
            "Inference Time: 0.12221479415893555\n",
            "Inference Time: 0.1135551929473877\n",
            "Inference Time: 0.11772942543029785\n",
            "Inference Time: 0.12189769744873047\n",
            "Inference Time: 0.12514519691467285\n",
            "Inference Time: 0.11913800239562988\n",
            "Inference Time: 0.12941193580627441\n",
            "Inference Time: 0.1178746223449707\n",
            "Inference Time: 0.13102149963378906\n",
            "Inference Time: 0.11867833137512207\n",
            "Inference Time: 0.11425995826721191\n",
            "Inference Time: 0.1166379451751709\n",
            "Inference Time: 0.12007856369018555\n",
            "Inference Time: 0.1234889030456543\n",
            "Inference Time: 0.1196908950805664\n",
            "Inference Time: 0.11764764785766602\n",
            "Inference Time: 0.12355494499206543\n",
            "Inference Time: 0.12274932861328125\n",
            "Inference Time: 0.11162495613098145\n",
            "Inference Time: 0.119598388671875\n",
            "Inference Time: 0.1122596263885498\n",
            "Inference Time: 0.11830735206604004\n",
            "Inference Time: 0.12309694290161133\n",
            "Inference Time: 0.11610198020935059\n",
            "Inference Time: 0.11733865737915039\n",
            "Inference Time: 0.12925386428833008\n",
            "Inference Time: 0.12311744689941406\n",
            "Inference Time: 0.11703157424926758\n",
            "Inference Time: 0.11451935768127441\n",
            "Inference Time: 0.1381239891052246\n",
            "Inference Time: 0.11756300926208496\n",
            "Inference Time: 0.1146702766418457\n",
            "Inference Time: 0.1172170639038086\n",
            "Inference Time: 0.11218714714050293\n",
            "Inference Time: 0.12346673011779785\n",
            "Inference Time: 0.12113785743713379\n",
            "Inference Time: 0.12508082389831543\n",
            "Inference Time: 0.1210322380065918\n",
            "Inference Time: 0.11211061477661133\n",
            "Inference Time: 0.13063502311706543\n",
            "Inference Time: 0.11387443542480469\n",
            "Inference Time: 0.12363338470458984\n",
            "Inference Time: 0.12055754661560059\n",
            "Inference Time: 0.1293480396270752\n",
            "Inference Time: 0.1330578327178955\n",
            "Inference Time: 0.11654520034790039\n",
            "Inference Time: 0.13887882232666016\n",
            "Inference Time: 0.1203005313873291\n",
            "Inference Time: 0.11507725715637207\n",
            "Inference Time: 0.139190673828125\n",
            "Inference Time: 0.12865376472473145\n",
            "Inference Time: 0.13351035118103027\n",
            "Inference Time: 0.11265444755554199\n",
            "Inference Time: 0.12196850776672363\n",
            "Inference Time: 0.1251845359802246\n",
            "Inference Time: 0.11629915237426758\n",
            "Inference Time: 0.13026952743530273\n",
            "Inference Time: 0.11660623550415039\n",
            "Inference Time: 0.125199556350708\n",
            "Inference Time: 0.12342214584350586\n",
            "Inference Time: 0.1154031753540039\n",
            "Inference Time: 0.1219336986541748\n",
            "Inference Time: 0.1165473461151123\n",
            "Inference Time: 0.11969256401062012\n",
            "Inference Time: 0.11243009567260742\n",
            "Inference Time: 0.11772918701171875\n",
            "Inference Time: 0.1438732147216797\n",
            "Inference Time: 0.12073183059692383\n",
            "Inference Time: 0.1113126277923584\n",
            "Inference Time: 0.1225883960723877\n",
            "Inference Time: 0.1141963005065918\n",
            "Inference Time: 0.12477612495422363\n",
            "Inference Time: 0.11628913879394531\n",
            "Inference Time: 0.1224057674407959\n",
            "Inference Time: 0.11456418037414551\n",
            "Inference Time: 0.13000869750976562\n",
            "Inference Time: 0.1331932544708252\n",
            "Inference Time: 0.1195518970489502\n",
            "Inference Time: 0.21003079414367676\n",
            "Inference Time: 0.3345932960510254\n",
            "Inference Time: 0.18205952644348145\n",
            "Inference Time: 0.1858668327331543\n",
            "Inference Time: 0.21559524536132812\n",
            "Inference Time: 0.1797335147857666\n",
            "Inference Time: 0.4073960781097412\n",
            "Inference Time: 0.408642053604126\n",
            "Inference Time: 0.42752504348754883\n",
            "Inference Time: 0.4495229721069336\n",
            "Inference Time: 0.3657693862915039\n",
            "Inference Time: 0.5103039741516113\n",
            "Inference Time: 0.6003038883209229\n",
            "Inference Time: 0.44085121154785156\n",
            "Inference Time: 0.5304880142211914\n",
            "Inference Time: 0.33161115646362305\n",
            "Inference Time: 0.5797827243804932\n",
            "Inference Time: 0.16646480560302734\n",
            "Inference Time: 0.19714665412902832\n",
            "Inference Time: 0.17678403854370117\n",
            "Inference Time: 0.1408398151397705\n",
            "Inference Time: 0.12097287178039551\n",
            "Inference Time: 0.1210489273071289\n",
            "Inference Time: 0.11491537094116211\n",
            "Inference Time: 0.12525200843811035\n",
            "Inference Time: 0.11040186882019043\n",
            "Inference Time: 0.12150335311889648\n",
            "Inference Time: 0.11339783668518066\n",
            "Inference Time: 0.1399211883544922\n",
            "Inference Time: 0.11609578132629395\n",
            "Inference Time: 0.12124800682067871\n",
            "Inference Time: 0.1205897331237793\n",
            "Inference Time: 0.11739659309387207\n",
            "Inference Time: 0.11254000663757324\n",
            "Inference Time: 0.12359213829040527\n",
            "Inference Time: 0.12305283546447754\n",
            "Inference Time: 0.14265036582946777\n",
            "Inference Time: 0.10763120651245117\n",
            "Inference Time: 0.13201904296875\n",
            "Inference Time: 0.1199493408203125\n",
            "Inference Time: 0.1204986572265625\n",
            "Inference Time: 0.11825847625732422\n",
            "Inference Time: 0.12583160400390625\n",
            "Inference Time: 0.11910891532897949\n",
            "Inference Time: 0.14281296730041504\n",
            "Inference Time: 0.12317514419555664\n",
            "Inference Time: 0.1236729621887207\n",
            "Inference Time: 0.11124634742736816\n",
            "Inference Time: 0.13524341583251953\n",
            "Inference Time: 0.12020182609558105\n",
            "Inference Time: 0.12119078636169434\n",
            "Inference Time: 0.12355351448059082\n",
            "Inference Time: 0.13278913497924805\n",
            "Inference Time: 0.11839079856872559\n",
            "Inference Time: 0.12058401107788086\n",
            "Inference Time: 0.11201834678649902\n",
            "Inference Time: 0.1266651153564453\n",
            "Inference Time: 0.11819100379943848\n",
            "Inference Time: 0.1409912109375\n",
            "Inference Time: 0.12116003036499023\n",
            "Inference Time: 0.14669442176818848\n",
            "Inference Time: 0.12072086334228516\n",
            "Inference Time: 0.1265871524810791\n",
            "Inference Time: 0.11660957336425781\n",
            "Inference Time: 0.11500430107116699\n",
            "Inference Time: 0.11174702644348145\n",
            "Inference Time: 0.12732315063476562\n",
            "Inference Time: 0.12616324424743652\n",
            "Inference Time: 0.13946127891540527\n",
            "Inference Time: 0.12239527702331543\n",
            "Inference Time: 0.1245889663696289\n",
            "Inference Time: 0.11341190338134766\n",
            "Inference Time: 0.11881804466247559\n",
            "Inference Time: 0.1152808666229248\n",
            "Inference Time: 0.11866545677185059\n",
            "Inference Time: 0.12358975410461426\n",
            "Inference Time: 0.11937355995178223\n",
            "Inference Time: 0.1307203769683838\n",
            "Inference Time: 0.14672541618347168\n",
            "Inference Time: 0.11864733695983887\n",
            "Inference Time: 0.12431049346923828\n",
            "Inference Time: 0.1144402027130127\n",
            "Inference Time: 0.11551022529602051\n",
            "Inference Time: 0.11992883682250977\n",
            "Inference Time: 0.13397789001464844\n",
            "Inference Time: 0.130279541015625\n",
            "Inference Time: 0.1154928207397461\n",
            "Inference Time: 0.11723160743713379\n",
            "Inference Time: 0.12974786758422852\n",
            "Inference Time: 0.11161208152770996\n",
            "Inference Time: 0.11949610710144043\n",
            "Inference Time: 0.11527609825134277\n",
            "Inference Time: 0.11676287651062012\n",
            "Inference Time: 0.12335920333862305\n",
            "Inference Time: 0.1531074047088623\n",
            "Inference Time: 0.11010956764221191\n",
            "Inference Time: 0.11975240707397461\n",
            "Inference Time: 0.10988235473632812\n",
            "Inference Time: 0.13195443153381348\n",
            "Inference Time: 0.12052512168884277\n",
            "Inference Time: 0.1199650764465332\n",
            "Inference Time: 0.11952781677246094\n",
            "Inference Time: 0.1248464584350586\n",
            "Inference Time: 0.11699676513671875\n",
            "Inference Time: 0.1141507625579834\n",
            "Inference Time: 0.1165769100189209\n",
            "Inference Time: 0.12677431106567383\n",
            "Inference Time: 0.11960124969482422\n",
            "Inference Time: 0.13913702964782715\n",
            "Inference Time: 0.11603450775146484\n",
            "Inference Time: 0.1391925811767578\n",
            "Inference Time: 0.11183500289916992\n",
            "Inference Time: 0.11972761154174805\n",
            "Inference Time: 0.11919355392456055\n",
            "Inference Time: 0.11583757400512695\n",
            "Inference Time: 0.1201024055480957\n",
            "Inference Time: 0.11991620063781738\n",
            "Inference Time: 0.11423897743225098\n",
            "Inference Time: 0.14983725547790527\n",
            "Inference Time: 0.11389303207397461\n",
            "Inference Time: 0.11680316925048828\n",
            "Inference Time: 0.12026095390319824\n",
            "Inference Time: 0.11687088012695312\n",
            "Inference Time: 0.11784720420837402\n",
            "Inference Time: 0.11789584159851074\n",
            "Inference Time: 0.11011171340942383\n",
            "Inference Time: 0.12288117408752441\n",
            "Inference Time: 0.12676095962524414\n",
            "Inference Time: 0.12932777404785156\n",
            "Inference Time: 0.12071633338928223\n",
            "Inference Time: 0.12358283996582031\n",
            "Inference Time: 0.11076760292053223\n",
            "Inference Time: 0.12579894065856934\n",
            "Inference Time: 0.1111001968383789\n",
            "Inference Time: 0.11726498603820801\n",
            "Inference Time: 0.13081932067871094\n",
            "Inference Time: 0.11226534843444824\n",
            "Inference Time: 0.1236581802368164\n",
            "Inference Time: 0.12813663482666016\n",
            "Inference Time: 0.11828279495239258\n",
            "Inference Time: 0.1258678436279297\n",
            "Inference Time: 0.11241793632507324\n",
            "Inference Time: 0.1202094554901123\n",
            "Inference Time: 0.11580848693847656\n",
            "Inference Time: 0.12725448608398438\n",
            "Inference Time: 0.11501097679138184\n",
            "Inference Time: 0.12027573585510254\n",
            "Inference Time: 0.12181472778320312\n",
            "Inference Time: 0.12727093696594238\n",
            "Inference Time: 0.1171875\n",
            "Inference Time: 0.11832618713378906\n",
            "Inference Time: 0.11679458618164062\n",
            "Inference Time: 0.13153481483459473\n",
            "Inference Time: 0.11416053771972656\n",
            "Inference Time: 0.12204957008361816\n",
            "Inference Time: 0.1260218620300293\n",
            "Inference Time: 0.11877083778381348\n",
            "Inference Time: 0.11738109588623047\n",
            "Inference Time: 0.1284012794494629\n",
            "Inference Time: 0.11754894256591797\n",
            "Inference Time: 0.12977886199951172\n",
            "Inference Time: 0.11172223091125488\n",
            "Inference Time: 0.12111067771911621\n",
            "Inference Time: 0.1118321418762207\n",
            "Inference Time: 0.1233670711517334\n",
            "Inference Time: 0.11587119102478027\n",
            "Inference Time: 0.12190413475036621\n",
            "Inference Time: 0.1202852725982666\n",
            "Inference Time: 0.12697696685791016\n",
            "Inference Time: 0.12264490127563477\n",
            "Inference Time: 0.11579132080078125\n",
            "Inference Time: 0.1110837459564209\n",
            "Inference Time: 0.12281584739685059\n",
            "Inference Time: 0.1136484146118164\n",
            "Inference Time: 0.121185302734375\n",
            "Inference Time: 0.11290836334228516\n",
            "Inference Time: 0.11703848838806152\n",
            "Inference Time: 0.12732148170471191\n",
            "Inference Time: 0.14954447746276855\n",
            "Inference Time: 0.11873292922973633\n",
            "Inference Time: 0.11680817604064941\n",
            "Inference Time: 0.11926126480102539\n",
            "Inference Time: 0.12393689155578613\n",
            "Inference Time: 0.11870980262756348\n",
            "Inference Time: 0.12273311614990234\n",
            "Inference Time: 0.11769628524780273\n",
            "Inference Time: 0.12612581253051758\n",
            "Inference Time: 0.11878371238708496\n",
            "Inference Time: 0.13096857070922852\n",
            "Inference Time: 0.12097620964050293\n",
            "Inference Time: 0.11454916000366211\n",
            "Inference Time: 0.11400771141052246\n",
            "Inference Time: 0.11562824249267578\n",
            "Inference Time: 0.10851335525512695\n",
            "Inference Time: 0.13439488410949707\n",
            "Inference Time: 0.10995173454284668\n",
            "Inference Time: 0.12445521354675293\n",
            "Inference Time: 0.11553025245666504\n",
            "Inference Time: 0.1263573169708252\n",
            "Inference Time: 0.11455035209655762\n",
            "Inference Time: 0.11196494102478027\n",
            "Inference Time: 0.11290097236633301\n",
            "Inference Time: 0.1304168701171875\n",
            "Inference Time: 0.16913104057312012\n",
            "Inference Time: 0.41552186012268066\n",
            "Inference Time: 0.15865111351013184\n",
            "Inference Time: 0.12421631813049316\n",
            "Inference Time: 0.12112045288085938\n",
            "Inference Time: 0.13411498069763184\n",
            "Inference Time: 0.32985663414001465\n",
            "Inference Time: 0.2703268527984619\n",
            "Inference Time: 0.11054611206054688\n",
            "Inference Time: 0.11672759056091309\n",
            "Inference Time: 0.13158822059631348\n",
            "Inference Time: 0.11742329597473145\n",
            "Inference Time: 0.12200307846069336\n",
            "Inference Time: 0.11880803108215332\n",
            "Inference Time: 0.11350655555725098\n",
            "Inference Time: 0.12834525108337402\n",
            "Inference Time: 0.1097874641418457\n",
            "Inference Time: 0.11677789688110352\n",
            "Inference Time: 0.12346959114074707\n",
            "Inference Time: 0.11940455436706543\n",
            "Inference Time: 0.1155245304107666\n",
            "Inference Time: 0.1223909854888916\n",
            "Inference Time: 0.11972761154174805\n",
            "Inference Time: 0.11992692947387695\n",
            "Inference Time: 0.11290693283081055\n",
            "Inference Time: 0.12753939628601074\n",
            "Inference Time: 0.11903977394104004\n",
            "Inference Time: 0.13591217994689941\n",
            "Inference Time: 0.12950563430786133\n",
            "Inference Time: 0.11911487579345703\n",
            "Inference Time: 0.12390947341918945\n",
            "Inference Time: 0.11799025535583496\n",
            "Inference Time: 0.11311793327331543\n",
            "Inference Time: 0.11185574531555176\n",
            "Inference Time: 0.11400556564331055\n",
            "Inference Time: 0.14469480514526367\n",
            "Inference Time: 0.11778712272644043\n",
            "Inference Time: 0.12512993812561035\n",
            "Inference Time: 0.11252331733703613\n",
            "Inference Time: 0.1229701042175293\n",
            "Inference Time: 0.12512850761413574\n",
            "Inference Time: 0.12301182746887207\n",
            "Inference Time: 0.11509084701538086\n",
            "Inference Time: 0.1313033103942871\n",
            "Inference Time: 0.12516164779663086\n",
            "Inference Time: 0.13303112983703613\n",
            "Inference Time: 0.11427474021911621\n",
            "Inference Time: 0.12154459953308105\n",
            "Inference Time: 0.1157689094543457\n",
            "Inference Time: 0.11531782150268555\n",
            "Inference Time: 0.11676263809204102\n",
            "Inference Time: 0.12929534912109375\n",
            "Inference Time: 0.1178731918334961\n",
            "Inference Time: 0.13790607452392578\n",
            "Inference Time: 0.11208987236022949\n",
            "Inference Time: 0.13292813301086426\n",
            "Inference Time: 0.12473702430725098\n",
            "Inference Time: 0.11612272262573242\n",
            "Inference Time: 0.11199474334716797\n",
            "Inference Time: 0.1231389045715332\n",
            "Inference Time: 0.12578725814819336\n",
            "Inference Time: 0.12525439262390137\n",
            "Inference Time: 0.11235594749450684\n",
            "Inference Time: 0.12125468254089355\n",
            "Inference Time: 0.1210641860961914\n",
            "Inference Time: 0.13059067726135254\n",
            "Inference Time: 0.11899590492248535\n",
            "Inference Time: 0.11679935455322266\n",
            "Inference Time: 0.126054048538208\n",
            "Inference Time: 0.12458515167236328\n",
            "Inference Time: 0.11478114128112793\n",
            "Inference Time: 0.12543034553527832\n",
            "Inference Time: 0.11577010154724121\n",
            "Inference Time: 0.11588764190673828\n",
            "Inference Time: 0.11573147773742676\n",
            "Inference Time: 0.13435864448547363\n",
            "Inference Time: 0.12876629829406738\n",
            "Inference Time: 0.11698198318481445\n",
            "Inference Time: 0.11577463150024414\n",
            "Inference Time: 0.12153959274291992\n",
            "Inference Time: 0.11180424690246582\n",
            "Inference Time: 0.12336063385009766\n",
            "Inference Time: 0.11807012557983398\n",
            "Inference Time: 0.13275647163391113\n",
            "Inference Time: 0.1290299892425537\n",
            "Inference Time: 0.14044904708862305\n",
            "Inference Time: 0.11201119422912598\n",
            "Inference Time: 0.1220388412475586\n",
            "Inference Time: 0.11699795722961426\n",
            "Inference Time: 0.12387514114379883\n",
            "Inference Time: 0.1106252670288086\n",
            "Inference Time: 0.1165931224822998\n",
            "Inference Time: 0.1140751838684082\n",
            "Inference Time: 0.13233351707458496\n",
            "Inference Time: 0.11930441856384277\n",
            "Inference Time: 0.13721537590026855\n",
            "Inference Time: 0.11095643043518066\n",
            "Inference Time: 0.11777591705322266\n",
            "Inference Time: 0.11774230003356934\n",
            "Inference Time: 0.11951875686645508\n",
            "Inference Time: 0.11619997024536133\n",
            "Inference Time: 0.12905573844909668\n",
            "Inference Time: 0.11163902282714844\n",
            "Inference Time: 0.11937880516052246\n",
            "Inference Time: 0.11272716522216797\n",
            "Inference Time: 0.1305103302001953\n",
            "Inference Time: 0.11613750457763672\n",
            "Inference Time: 0.11698079109191895\n",
            "Inference Time: 0.11984705924987793\n",
            "Inference Time: 0.13325929641723633\n",
            "Inference Time: 0.11836409568786621\n",
            "Inference Time: 0.12038421630859375\n",
            "Inference Time: 0.11789917945861816\n",
            "Inference Time: 0.12225127220153809\n",
            "Inference Time: 0.11143159866333008\n",
            "Inference Time: 0.13584566116333008\n",
            "Inference Time: 0.1117095947265625\n",
            "Inference Time: 0.1298515796661377\n",
            "Inference Time: 0.12484264373779297\n",
            "Inference Time: 0.11423325538635254\n",
            "Inference Time: 0.1161644458770752\n",
            "Inference Time: 0.12203431129455566\n",
            "Inference Time: 0.12005019187927246\n",
            "Inference Time: 0.11824274063110352\n",
            "Inference Time: 0.12163043022155762\n",
            "Inference Time: 0.13251352310180664\n",
            "Inference Time: 0.12949371337890625\n",
            "Inference Time: 0.12411141395568848\n",
            "Inference Time: 0.11716771125793457\n",
            "Inference Time: 0.11242818832397461\n",
            "Inference Time: 0.11506319046020508\n",
            "Inference Time: 0.1190023422241211\n",
            "Inference Time: 0.1141049861907959\n",
            "Inference Time: 0.11729788780212402\n",
            "Inference Time: 0.13207292556762695\n",
            "Inference Time: 0.1368415355682373\n",
            "Inference Time: 0.12591934204101562\n",
            "Inference Time: 0.11594319343566895\n",
            "Inference Time: 0.11452221870422363\n",
            "Inference Time: 0.12040090560913086\n",
            "Inference Time: 0.10996365547180176\n",
            "Inference Time: 0.12135100364685059\n",
            "Inference Time: 0.11340928077697754\n",
            "Inference Time: 0.1298985481262207\n",
            "Inference Time: 0.11914396286010742\n",
            "Inference Time: 0.14757013320922852\n",
            "Inference Time: 0.11740303039550781\n",
            "Inference Time: 0.11852478981018066\n",
            "Inference Time: 0.11587858200073242\n",
            "Inference Time: 0.12496733665466309\n",
            "Inference Time: 0.11547970771789551\n",
            "Inference Time: 0.12985634803771973\n",
            "Inference Time: 0.12445640563964844\n",
            "Inference Time: 0.11908602714538574\n",
            "Inference Time: 0.11617755889892578\n",
            "Inference Time: 0.1356644630432129\n",
            "Inference Time: 0.11440706253051758\n",
            "Inference Time: 0.12309932708740234\n",
            "Inference Time: 0.1183309555053711\n",
            "Inference Time: 0.13257265090942383\n",
            "Inference Time: 0.12152743339538574\n",
            "Inference Time: 0.11635494232177734\n",
            "Inference Time: 0.11861419677734375\n",
            "Inference Time: 0.1137545108795166\n",
            "Inference Time: 0.11310243606567383\n",
            "Inference Time: 0.13214421272277832\n",
            "Inference Time: 0.353229284286499\n",
            "Inference Time: 0.43552350997924805\n",
            "Inference Time: 0.286482572555542\n",
            "Inference Time: 0.11461377143859863\n",
            "Inference Time: 0.12687993049621582\n",
            "Inference Time: 0.11303830146789551\n",
            "Inference Time: 0.12124776840209961\n",
            "Inference Time: 0.11187863349914551\n",
            "Inference Time: 0.11786341667175293\n",
            "Inference Time: 0.12458348274230957\n",
            "Inference Time: 0.12583327293395996\n",
            "Inference Time: 0.12824463844299316\n",
            "Inference Time: 0.13094830513000488\n",
            "Inference Time: 0.11760973930358887\n",
            "Inference Time: 0.11570429801940918\n",
            "Inference Time: 0.11424827575683594\n",
            "Inference Time: 0.11817455291748047\n",
            "Inference Time: 0.11995410919189453\n",
            "Inference Time: 0.12386584281921387\n",
            "Inference Time: 0.124267578125\n",
            "Inference Time: 0.12829089164733887\n",
            "Inference Time: 0.12108111381530762\n",
            "Inference Time: 0.12031245231628418\n",
            "Inference Time: 0.11762595176696777\n",
            "Inference Time: 0.11489558219909668\n",
            "Inference Time: 0.1205596923828125\n",
            "Inference Time: 0.12364459037780762\n",
            "Inference Time: 0.12086176872253418\n",
            "Inference Time: 0.12752223014831543\n",
            "Inference Time: 0.1401820182800293\n",
            "Inference Time: 0.12024784088134766\n",
            "Inference Time: 0.11606860160827637\n",
            "Inference Time: 0.1232767105102539\n",
            "Inference Time: 0.13381600379943848\n",
            "Inference Time: 0.12289786338806152\n",
            "Inference Time: 0.1233983039855957\n",
            "Inference Time: 0.1200261116027832\n",
            "Inference Time: 0.13168883323669434\n",
            "Inference Time: 0.11475157737731934\n",
            "Inference Time: 0.11970806121826172\n",
            "Inference Time: 0.11675333976745605\n",
            "Inference Time: 0.10963129997253418\n",
            "Inference Time: 0.12732887268066406\n",
            "Inference Time: 0.11628079414367676\n",
            "Inference Time: 0.11587762832641602\n",
            "Inference Time: 0.11215567588806152\n",
            "Inference Time: 0.12568283081054688\n",
            "Inference Time: 0.11708354949951172\n",
            "Inference Time: 0.13164353370666504\n",
            "Inference Time: 0.13246417045593262\n",
            "Inference Time: 0.1308150291442871\n",
            "Inference Time: 0.12684988975524902\n",
            "Inference Time: 0.13081836700439453\n",
            "Inference Time: 0.11835384368896484\n",
            "Inference Time: 0.13111066818237305\n",
            "Inference Time: 0.11218905448913574\n",
            "Inference Time: 0.12290644645690918\n",
            "Inference Time: 0.11903858184814453\n",
            "Inference Time: 0.12361478805541992\n",
            "Inference Time: 0.12975621223449707\n",
            "Inference Time: 0.12263870239257812\n",
            "Inference Time: 0.12424612045288086\n",
            "Inference Time: 0.13228178024291992\n",
            "Inference Time: 0.11783742904663086\n",
            "Inference Time: 0.11542963981628418\n",
            "Inference Time: 0.11116266250610352\n",
            "Inference Time: 0.1248922348022461\n",
            "Inference Time: 0.11449265480041504\n",
            "Inference Time: 0.1220848560333252\n",
            "Inference Time: 0.12283658981323242\n",
            "Inference Time: 0.12932467460632324\n",
            "Inference Time: 0.11710429191589355\n",
            "Inference Time: 0.11983966827392578\n",
            "Inference Time: 0.11342000961303711\n",
            "Inference Time: 0.11744546890258789\n",
            "Inference Time: 0.11130547523498535\n",
            "Inference Time: 0.12232398986816406\n",
            "Inference Time: 0.11834931373596191\n",
            "Inference Time: 0.1213083267211914\n",
            "Inference Time: 0.13570547103881836\n",
            "Inference Time: 0.1176292896270752\n",
            "Inference Time: 0.11499285697937012\n",
            "Inference Time: 0.12086176872253418\n",
            "Inference Time: 0.10987973213195801\n",
            "Inference Time: 0.12522077560424805\n",
            "Inference Time: 0.11569643020629883\n",
            "Inference Time: 0.12241315841674805\n",
            "Inference Time: 0.12434244155883789\n",
            "Inference Time: 0.11859941482543945\n",
            "Inference Time: 0.13071084022521973\n",
            "Inference Time: 0.11950087547302246\n",
            "Inference Time: 0.11800575256347656\n",
            "Inference Time: 0.12006855010986328\n",
            "Inference Time: 0.11870479583740234\n",
            "Inference Time: 0.11861848831176758\n",
            "Inference Time: 0.12965631484985352\n",
            "Inference Time: 0.11534547805786133\n",
            "Inference Time: 0.11871004104614258\n",
            "Inference Time: 0.12707781791687012\n",
            "Inference Time: 0.1209871768951416\n",
            "Inference Time: 0.12241244316101074\n",
            "Inference Time: 0.11281776428222656\n",
            "Inference Time: 0.11797666549682617\n",
            "Inference Time: 0.1155402660369873\n",
            "Inference Time: 0.12938380241394043\n",
            "Inference Time: 0.11090207099914551\n",
            "Inference Time: 0.12386274337768555\n",
            "Inference Time: 0.11285400390625\n",
            "Inference Time: 0.11789631843566895\n",
            "Inference Time: 0.1270458698272705\n",
            "Inference Time: 0.12139534950256348\n",
            "Inference Time: 0.10779213905334473\n",
            "Inference Time: 0.13193893432617188\n",
            "Inference Time: 0.12417411804199219\n",
            "Inference Time: 0.11415457725524902\n",
            "Inference Time: 0.11222243309020996\n",
            "Inference Time: 0.12823224067687988\n",
            "Inference Time: 0.11390018463134766\n",
            "Inference Time: 0.12141656875610352\n",
            "Inference Time: 0.12448811531066895\n",
            "Inference Time: 0.12338590621948242\n",
            "Inference Time: 0.12440133094787598\n",
            "Inference Time: 0.11435794830322266\n",
            "Inference Time: 0.12522077560424805\n",
            "Inference Time: 0.1213541030883789\n",
            "Inference Time: 0.11202335357666016\n",
            "Inference Time: 0.12974858283996582\n",
            "Inference Time: 0.10971951484680176\n",
            "Inference Time: 0.1210629940032959\n",
            "Inference Time: 0.1322476863861084\n",
            "Inference Time: 0.12216401100158691\n",
            "Inference Time: 0.11078977584838867\n",
            "Inference Time: 0.1332228183746338\n",
            "Inference Time: 0.11770796775817871\n",
            "Inference Time: 0.11812019348144531\n",
            "Inference Time: 0.1114659309387207\n",
            "Inference Time: 0.12115859985351562\n",
            "Inference Time: 0.12521123886108398\n",
            "Inference Time: 0.12127685546875\n",
            "Inference Time: 0.12750792503356934\n",
            "Inference Time: 0.1249542236328125\n",
            "Inference Time: 0.10998988151550293\n",
            "Inference Time: 0.11593151092529297\n",
            "Inference Time: 0.12393474578857422\n",
            "Inference Time: 0.11343550682067871\n",
            "Inference Time: 0.1105489730834961\n",
            "Inference Time: 0.13247060775756836\n",
            "Inference Time: 0.11090993881225586\n",
            "Inference Time: 0.12664294242858887\n",
            "Inference Time: 0.12335014343261719\n",
            "Inference Time: 0.47187113761901855\n",
            "Inference Time: 0.12262630462646484\n",
            "Inference Time: 0.11713480949401855\n",
            "Inference Time: 0.11440253257751465\n",
            "Inference Time: 0.12392807006835938\n",
            "Inference Time: 0.11054563522338867\n",
            "Inference Time: 0.11793279647827148\n",
            "Inference Time: 0.11167335510253906\n",
            "Inference Time: 0.12114191055297852\n",
            "Inference Time: 0.12736940383911133\n",
            "Inference Time: 0.12885761260986328\n",
            "Inference Time: 0.11898565292358398\n",
            "Inference Time: 0.11939096450805664\n",
            "Inference Time: 0.11720538139343262\n",
            "Inference Time: 0.12346363067626953\n",
            "Inference Time: 0.11632132530212402\n",
            "Inference Time: 0.12398338317871094\n",
            "Inference Time: 0.10996460914611816\n",
            "Inference Time: 0.13216662406921387\n",
            "Inference Time: 0.12598276138305664\n",
            "Inference Time: 0.11941313743591309\n",
            "Inference Time: 0.11811327934265137\n",
            "Inference Time: 0.1157829761505127\n",
            "Inference Time: 0.1103205680847168\n",
            "Inference Time: 0.12178897857666016\n",
            "Inference Time: 0.11346673965454102\n",
            "Inference Time: 0.13837122917175293\n",
            "Inference Time: 0.12488770484924316\n",
            "Inference Time: 0.1212005615234375\n",
            "Inference Time: 0.13175082206726074\n",
            "Inference Time: 0.12201070785522461\n",
            "Inference Time: 0.13133907318115234\n",
            "Inference Time: 0.1197350025177002\n",
            "Inference Time: 0.11757683753967285\n",
            "Inference Time: 0.11752963066101074\n",
            "Inference Time: 0.12546038627624512\n",
            "Inference Time: 0.12191534042358398\n",
            "Inference Time: 0.1110692024230957\n",
            "Inference Time: 0.12571954727172852\n",
            "Inference Time: 0.12380504608154297\n",
            "Inference Time: 0.1252741813659668\n",
            "Inference Time: 0.11176800727844238\n",
            "Inference Time: 0.1175081729888916\n",
            "Inference Time: 0.13477134704589844\n",
            "Inference Time: 0.11467981338500977\n",
            "Inference Time: 0.11785483360290527\n",
            "Inference Time: 0.12058329582214355\n",
            "Inference Time: 0.11278057098388672\n",
            "Inference Time: 0.12116789817810059\n",
            "Inference Time: 0.12324047088623047\n",
            "Inference Time: 0.1264023780822754\n",
            "Inference Time: 0.13045573234558105\n",
            "Inference Time: 0.1202249526977539\n",
            "Inference Time: 0.11760473251342773\n",
            "Inference Time: 0.1181342601776123\n",
            "Inference Time: 0.11655616760253906\n",
            "Inference Time: 0.11576342582702637\n",
            "Inference Time: 0.11157560348510742\n",
            "Inference Time: 0.12128162384033203\n",
            "Inference Time: 0.12870383262634277\n",
            "Inference Time: 0.1329653263092041\n",
            "Inference Time: 0.11703824996948242\n",
            "Inference Time: 0.12190032005310059\n",
            "Inference Time: 0.11384129524230957\n",
            "Inference Time: 0.13627243041992188\n",
            "Inference Time: 0.11806464195251465\n",
            "Inference Time: 0.11510491371154785\n",
            "Inference Time: 0.12232685089111328\n",
            "Inference Time: 0.1335914134979248\n",
            "Inference Time: 0.12362074851989746\n",
            "Inference Time: 0.12582159042358398\n",
            "Inference Time: 0.11607837677001953\n",
            "Inference Time: 0.12033319473266602\n",
            "Inference Time: 0.11166548728942871\n",
            "Inference Time: 0.11775040626525879\n",
            "Inference Time: 0.1282973289489746\n",
            "Inference Time: 0.1331343650817871\n",
            "Inference Time: 0.11244797706604004\n",
            "Inference Time: 0.11918878555297852\n",
            "Inference Time: 0.12877202033996582\n",
            "Inference Time: 0.11812019348144531\n",
            "Inference Time: 0.11372828483581543\n",
            "Inference Time: 0.11890196800231934\n",
            "Inference Time: 0.11675786972045898\n",
            "Inference Time: 0.12511539459228516\n",
            "Inference Time: 0.12213468551635742\n",
            "Inference Time: 0.11699151992797852\n",
            "Inference Time: 0.11018061637878418\n",
            "Inference Time: 0.11538434028625488\n",
            "Inference Time: 0.12120985984802246\n",
            "Inference Time: 0.1279432773590088\n",
            "Inference Time: 0.11585092544555664\n",
            "Inference Time: 0.12357425689697266\n",
            "Inference Time: 0.13270998001098633\n",
            "Inference Time: 0.1177978515625\n",
            "Inference Time: 0.11320972442626953\n",
            "Inference Time: 0.11935949325561523\n",
            "Inference Time: 0.11667823791503906\n",
            "Inference Time: 0.12735843658447266\n",
            "Inference Time: 0.12738943099975586\n",
            "Inference Time: 0.12041640281677246\n",
            "Inference Time: 0.12497377395629883\n",
            "Inference Time: 0.11825847625732422\n",
            "Inference Time: 0.11757564544677734\n",
            "Inference Time: 0.1294252872467041\n",
            "Inference Time: 0.11568593978881836\n",
            "Inference Time: 0.12207698822021484\n",
            "Inference Time: 0.11118435859680176\n",
            "Inference Time: 0.12772274017333984\n",
            "Inference Time: 0.14413928985595703\n",
            "Inference Time: 0.12520527839660645\n",
            "Inference Time: 0.11147952079772949\n",
            "Inference Time: 0.1181325912475586\n",
            "Inference Time: 0.11345601081848145\n",
            "Inference Time: 0.12114667892456055\n",
            "Inference Time: 0.11373639106750488\n",
            "Inference Time: 0.12021470069885254\n",
            "Inference Time: 0.11170816421508789\n",
            "Inference Time: 0.1365189552307129\n",
            "Inference Time: 0.12571167945861816\n",
            "Inference Time: 0.12114453315734863\n",
            "Inference Time: 0.11121034622192383\n",
            "Inference Time: 0.12412214279174805\n",
            "Inference Time: 0.11625838279724121\n",
            "Inference Time: 0.11655783653259277\n",
            "Inference Time: 0.11700105667114258\n",
            "Inference Time: 0.131988525390625\n",
            "Inference Time: 0.11398625373840332\n",
            "Inference Time: 0.11256217956542969\n",
            "Inference Time: 0.13362360000610352\n",
            "Inference Time: 0.12155532836914062\n",
            "Inference Time: 0.11459136009216309\n",
            "Inference Time: 0.12667298316955566\n",
            "Inference Time: 0.1152656078338623\n",
            "Inference Time: 0.1213541030883789\n",
            "Inference Time: 0.12173151969909668\n",
            "Inference Time: 0.11880970001220703\n",
            "Inference Time: 0.11592531204223633\n",
            "Inference Time: 0.11650252342224121\n",
            "Inference Time: 0.12439799308776855\n",
            "Inference Time: 0.11762046813964844\n",
            "Inference Time: 0.11139369010925293\n",
            "Inference Time: 0.12185001373291016\n",
            "Inference Time: 0.13074779510498047\n",
            "Inference Time: 0.11951041221618652\n",
            "Inference Time: 0.11069989204406738\n",
            "Inference Time: 0.12145328521728516\n",
            "Inference Time: 0.11385798454284668\n",
            "Inference Time: 0.1453866958618164\n",
            "Inference Time: 0.1283121109008789\n",
            "Inference Time: 0.11702251434326172\n",
            "Inference Time: 0.12862277030944824\n",
            "Inference Time: 0.13418006896972656\n",
            "Inference Time: 0.1181027889251709\n",
            "Inference Time: 0.12344050407409668\n",
            "Inference Time: 0.11640024185180664\n",
            "Inference Time: 0.11969780921936035\n",
            "Inference Time: 0.11208820343017578\n",
            "Inference Time: 0.12086677551269531\n",
            "Inference Time: 0.14376401901245117\n",
            "Inference Time: 0.12144160270690918\n",
            "Inference Time: 0.12080264091491699\n",
            "Inference Time: 0.11549186706542969\n",
            "Inference Time: 0.11439085006713867\n",
            "Inference Time: 0.11790704727172852\n",
            "Inference Time: 0.12288546562194824\n",
            "Inference Time: 0.12036728858947754\n",
            "Inference Time: 0.11277031898498535\n",
            "Inference Time: 0.1272261142730713\n",
            "Inference Time: 0.12179112434387207\n",
            "Inference Time: 0.12175154685974121\n",
            "Inference Time: 0.11594152450561523\n",
            "Inference Time: 0.1228640079498291\n",
            "Inference Time: 0.10869145393371582\n",
            "Inference Time: 0.11444401741027832\n",
            "Inference Time: 0.12419557571411133\n",
            "Inference Time: 0.13022422790527344\n",
            "Inference Time: 0.1141974925994873\n",
            "Inference Time: 0.12073063850402832\n",
            "Inference Time: 0.12349176406860352\n",
            "Inference Time: 0.12325358390808105\n",
            "Inference Time: 0.1131443977355957\n",
            "Inference Time: 0.11888933181762695\n",
            "Inference Time: 0.12306022644042969\n",
            "Inference Time: 0.1258544921875\n",
            "Inference Time: 0.12259984016418457\n",
            "Inference Time: 0.11845231056213379\n",
            "Inference Time: 0.11952495574951172\n",
            "Inference Time: 0.12136077880859375\n",
            "Inference Time: 0.1398928165435791\n",
            "Inference Time: 0.12128043174743652\n",
            "Inference Time: 0.1225731372833252\n",
            "Inference Time: 0.1216742992401123\n",
            "Inference Time: 0.12912511825561523\n",
            "Inference Time: 0.11710309982299805\n",
            "Inference Time: 0.11412858963012695\n",
            "Inference Time: 0.11852502822875977\n",
            "Inference Time: 0.11836600303649902\n",
            "Inference Time: 0.11939024925231934\n",
            "Inference Time: 0.12850165367126465\n",
            "Inference Time: 0.1200101375579834\n",
            "Inference Time: 0.12332320213317871\n",
            "Inference Time: 0.12202692031860352\n",
            "Inference Time: 0.11188030242919922\n",
            "Inference Time: 0.11705183982849121\n",
            "Inference Time: 0.11652684211730957\n",
            "Inference Time: 0.1173238754272461\n",
            "Inference Time: 0.11612153053283691\n",
            "Inference Time: 0.12244248390197754\n",
            "Inference Time: 0.13608694076538086\n",
            "Inference Time: 0.12239956855773926\n",
            "Inference Time: 0.11561155319213867\n",
            "Inference Time: 0.11620426177978516\n",
            "Inference Time: 0.11520695686340332\n",
            "Inference Time: 0.1217799186706543\n",
            "Inference Time: 0.10959696769714355\n",
            "Inference Time: 0.12322068214416504\n",
            "Inference Time: 0.1122283935546875\n",
            "Inference Time: 0.13109087944030762\n",
            "Inference Time: 0.12371683120727539\n",
            "Inference Time: 0.1291499137878418\n",
            "Inference Time: 0.1204826831817627\n",
            "Inference Time: 0.12192368507385254\n",
            "Inference Time: 0.11932659149169922\n",
            "Inference Time: 0.12127113342285156\n",
            "Inference Time: 0.11533045768737793\n",
            "Inference Time: 0.13194918632507324\n",
            "Inference Time: 0.11193633079528809\n",
            "Inference Time: 0.12117600440979004\n",
            "Inference Time: 0.13112783432006836\n",
            "Inference Time: 0.12199592590332031\n",
            "Inference Time: 0.11405014991760254\n",
            "Inference Time: 0.1376190185546875\n",
            "Inference Time: 0.12317085266113281\n",
            "Inference Time: 0.12657499313354492\n",
            "Inference Time: 0.11520624160766602\n",
            "Inference Time: 0.12081646919250488\n",
            "Inference Time: 0.11368584632873535\n",
            "Inference Time: 0.12243127822875977\n",
            "Inference Time: 0.12513375282287598\n",
            "Inference Time: 0.11736202239990234\n",
            "Inference Time: 0.11500406265258789\n",
            "Inference Time: 0.11665916442871094\n",
            "Inference Time: 0.1243598461151123\n",
            "Inference Time: 0.11802268028259277\n",
            "Inference Time: 0.11359763145446777\n",
            "Inference Time: 0.12069153785705566\n",
            "Inference Time: 0.11520099639892578\n",
            "Inference Time: 0.1271042823791504\n",
            "Inference Time: 0.12795257568359375\n",
            "Inference Time: 0.12543177604675293\n",
            "Inference Time: 0.1255021095275879\n",
            "Inference Time: 0.11416435241699219\n",
            "Inference Time: 0.12034082412719727\n",
            "Inference Time: 0.11770462989807129\n",
            "Inference Time: 0.11982607841491699\n",
            "Inference Time: 0.1229095458984375\n",
            "Inference Time: 0.11115384101867676\n",
            "Inference Time: 0.11754155158996582\n",
            "Inference Time: 0.14057660102844238\n",
            "Inference Time: 0.12619471549987793\n",
            "Inference Time: 0.11415338516235352\n",
            "Inference Time: 0.12147045135498047\n",
            "Inference Time: 0.11904430389404297\n",
            "Inference Time: 0.11680817604064941\n",
            "Inference Time: 0.11475205421447754\n",
            "Inference Time: 0.11828923225402832\n",
            "Inference Time: 0.11047673225402832\n",
            "Inference Time: 0.12879586219787598\n",
            "Inference Time: 0.12120699882507324\n",
            "Inference Time: 0.1280345916748047\n",
            "Inference Time: 0.11315608024597168\n",
            "Inference Time: 0.12136578559875488\n",
            "Inference Time: 0.12322211265563965\n",
            "Inference Time: 0.13138771057128906\n",
            "Inference Time: 0.11782693862915039\n",
            "Inference Time: 0.12414264678955078\n",
            "Inference Time: 0.1218116283416748\n",
            "Inference Time: 0.12246561050415039\n",
            "Inference Time: 0.12288165092468262\n",
            "Inference Time: 0.11847710609436035\n",
            "Inference Time: 0.11019420623779297\n",
            "Inference Time: 0.1201786994934082\n",
            "Inference Time: 0.11762261390686035\n",
            "Inference Time: 0.13002228736877441\n",
            "Inference Time: 0.12038516998291016\n",
            "Inference Time: 0.12297272682189941\n",
            "Inference Time: 0.12090563774108887\n",
            "Inference Time: 0.11956119537353516\n",
            "Inference Time: 0.13518261909484863\n",
            "Inference Time: 0.1188817024230957\n",
            "Inference Time: 0.11253762245178223\n",
            "Inference Time: 0.12691092491149902\n",
            "Inference Time: 0.1129755973815918\n",
            "Inference Time: 0.12251758575439453\n",
            "Inference Time: 0.11377167701721191\n",
            "Inference Time: 0.1208195686340332\n",
            "Inference Time: 0.11779999732971191\n",
            "Inference Time: 0.11746764183044434\n",
            "Inference Time: 0.12228178977966309\n",
            "Inference Time: 0.11233139038085938\n",
            "Inference Time: 0.12435746192932129\n",
            "Inference Time: 0.1260373592376709\n",
            "Inference Time: 0.11186766624450684\n",
            "Inference Time: 0.1232445240020752\n",
            "Inference Time: 0.11967802047729492\n",
            "Inference Time: 0.12257957458496094\n",
            "Inference Time: 0.12107658386230469\n",
            "Inference Time: 0.11852240562438965\n",
            "Inference Time: 0.13963532447814941\n",
            "Inference Time: 0.13327288627624512\n",
            "Inference Time: 0.1118316650390625\n",
            "Inference Time: 0.11913418769836426\n",
            "Inference Time: 0.11048007011413574\n",
            "Inference Time: 0.11513757705688477\n",
            "Inference Time: 0.11817073822021484\n",
            "Inference Time: 0.14037466049194336\n",
            "Inference Time: 0.1212759017944336\n",
            "Inference Time: 0.11778616905212402\n",
            "Inference Time: 0.1271979808807373\n",
            "Inference Time: 0.11409187316894531\n",
            "Inference Time: 0.12051892280578613\n",
            "Inference Time: 0.12804150581359863\n",
            "Inference Time: 0.11302876472473145\n",
            "Inference Time: 0.11999082565307617\n",
            "Inference Time: 0.11301946640014648\n",
            "Inference Time: 0.12769579887390137\n",
            "Inference Time: 0.11608338356018066\n",
            "Inference Time: 0.12130045890808105\n",
            "Inference Time: 0.12593507766723633\n",
            "Inference Time: 0.11717629432678223\n",
            "Inference Time: 0.11402297019958496\n",
            "Inference Time: 0.12324404716491699\n",
            "Inference Time: 0.12012147903442383\n",
            "Inference Time: 0.13392376899719238\n",
            "Inference Time: 0.12339282035827637\n",
            "Inference Time: 0.12176704406738281\n",
            "Inference Time: 0.11180710792541504\n",
            "Inference Time: 0.11321449279785156\n",
            "Inference Time: 0.1291639804840088\n",
            "Inference Time: 0.12070846557617188\n",
            "Inference Time: 0.11064028739929199\n",
            "Inference Time: 0.11489605903625488\n",
            "Inference Time: 0.1277296543121338\n",
            "Inference Time: 0.12352895736694336\n",
            "Inference Time: 0.1134331226348877\n",
            "Inference Time: 0.12141776084899902\n",
            "Inference Time: 0.11440730094909668\n",
            "Inference Time: 0.11265230178833008\n",
            "Inference Time: 0.12775921821594238\n",
            "Inference Time: 0.11680722236633301\n",
            "Inference Time: 0.1453409194946289\n",
            "Inference Time: 0.12032032012939453\n",
            "Inference Time: 0.1144707202911377\n",
            "Inference Time: 0.12221932411193848\n",
            "Inference Time: 0.11304211616516113\n",
            "Inference Time: 0.12241864204406738\n",
            "Inference Time: 0.11693882942199707\n",
            "Inference Time: 0.12136650085449219\n",
            "Inference Time: 0.13874197006225586\n",
            "Inference Time: 0.11499571800231934\n",
            "Inference Time: 0.11835002899169922\n",
            "Inference Time: 0.1246788501739502\n",
            "Inference Time: 0.11723875999450684\n",
            "Inference Time: 0.1226043701171875\n",
            "Inference Time: 0.10984301567077637\n",
            "Inference Time: 0.12247228622436523\n",
            "Inference Time: 0.11121869087219238\n",
            "Inference Time: 0.12772178649902344\n",
            "Inference Time: 0.13215279579162598\n",
            "Inference Time: 0.13350462913513184\n",
            "Inference Time: 0.12030673027038574\n",
            "Inference Time: 0.11909198760986328\n",
            "Inference Time: 0.11658787727355957\n",
            "Inference Time: 0.12128186225891113\n",
            "Inference Time: 0.12429666519165039\n",
            "Inference Time: 0.13439726829528809\n",
            "Inference Time: 0.11854100227355957\n",
            "Inference Time: 0.12173700332641602\n",
            "Inference Time: 0.12178564071655273\n",
            "Inference Time: 0.11385416984558105\n",
            "Inference Time: 0.11682391166687012\n",
            "Inference Time: 0.1297287940979004\n",
            "Inference Time: 0.12389612197875977\n",
            "Inference Time: 0.130997896194458\n",
            "Inference Time: 0.11393618583679199\n",
            "Inference Time: 0.11967062950134277\n",
            "Inference Time: 0.11513423919677734\n",
            "Inference Time: 0.1228482723236084\n",
            "Inference Time: 0.12496566772460938\n",
            "Inference Time: 0.12064099311828613\n",
            "Inference Time: 0.11878848075866699\n",
            "Inference Time: 0.1303088665008545\n",
            "Inference Time: 0.12557697296142578\n",
            "Inference Time: 0.1165168285369873\n",
            "Inference Time: 0.11399030685424805\n",
            "Inference Time: 0.11747550964355469\n",
            "Inference Time: 0.10966944694519043\n",
            "Inference Time: 0.1239018440246582\n",
            "Inference Time: 0.1303253173828125\n",
            "Inference Time: 0.13716888427734375\n",
            "Inference Time: 0.1369152069091797\n",
            "Inference Time: 0.11632132530212402\n",
            "Inference Time: 0.11457681655883789\n",
            "Inference Time: 0.12073135375976562\n",
            "Inference Time: 0.11210513114929199\n",
            "Inference Time: 0.12138795852661133\n",
            "Inference Time: 0.11646080017089844\n",
            "Inference Time: 0.11945986747741699\n",
            "Inference Time: 0.13394761085510254\n",
            "Inference Time: 0.12474894523620605\n",
            "Inference Time: 0.11336946487426758\n",
            "Inference Time: 0.11863398551940918\n",
            "Inference Time: 0.11775803565979004\n",
            "Inference Time: 0.12054157257080078\n",
            "Inference Time: 0.1279151439666748\n",
            "Inference Time: 0.12076735496520996\n",
            "Inference Time: 0.12488436698913574\n",
            "Inference Time: 0.12124419212341309\n",
            "Inference Time: 0.1246640682220459\n",
            "Inference Time: 0.12349104881286621\n",
            "Inference Time: 0.1136167049407959\n",
            "Inference Time: 0.11989402770996094\n",
            "Inference Time: 0.12455511093139648\n",
            "Inference Time: 0.11717820167541504\n",
            "Inference Time: 0.11740565299987793\n",
            "Inference Time: 0.13492035865783691\n",
            "Inference Time: 0.11677360534667969\n",
            "Inference Time: 0.12015533447265625\n",
            "Inference Time: 0.12935423851013184\n",
            "Inference Time: 0.1208045482635498\n",
            "Inference Time: 0.12586164474487305\n",
            "Inference Time: 0.1222994327545166\n",
            "Inference Time: 0.11472606658935547\n",
            "Inference Time: 0.1300039291381836\n",
            "Inference Time: 0.11821103096008301\n",
            "Inference Time: 0.11757993698120117\n",
            "Inference Time: 0.11599564552307129\n",
            "Inference Time: 0.12400078773498535\n",
            "Inference Time: 0.12483692169189453\n",
            "Inference Time: 0.12172460556030273\n",
            "Inference Time: 0.11537861824035645\n",
            "Inference Time: 0.13882017135620117\n",
            "Inference Time: 0.11653566360473633\n",
            "Inference Time: 0.11743569374084473\n",
            "Inference Time: 0.11432504653930664\n",
            "Inference Time: 0.11994290351867676\n",
            "Inference Time: 0.11330747604370117\n",
            "Inference Time: 0.11607098579406738\n",
            "Inference Time: 0.13081908226013184\n",
            "Inference Time: 0.1329662799835205\n",
            "Inference Time: 0.12049126625061035\n",
            "Inference Time: 0.11490511894226074\n",
            "Inference Time: 0.1104423999786377\n",
            "Inference Time: 0.11971735954284668\n",
            "Inference Time: 0.1193079948425293\n",
            "Inference Time: 0.12383437156677246\n",
            "Inference Time: 0.11275696754455566\n",
            "Inference Time: 0.12400531768798828\n",
            "Inference Time: 0.15011286735534668\n",
            "Inference Time: 0.11975240707397461\n",
            "Inference Time: 0.11635255813598633\n",
            "Inference Time: 0.11862301826477051\n",
            "Inference Time: 0.11509132385253906\n",
            "Inference Time: 0.11926531791687012\n",
            "Inference Time: 0.11148214340209961\n",
            "Inference Time: 0.12399840354919434\n",
            "Inference Time: 0.12428832054138184\n",
            "Inference Time: 0.11785221099853516\n",
            "Inference Time: 0.1344740390777588\n",
            "Inference Time: 0.12092447280883789\n",
            "Inference Time: 0.12307167053222656\n",
            "Inference Time: 0.13365769386291504\n",
            "Inference Time: 0.11861205101013184\n",
            "Inference Time: 0.11867237091064453\n",
            "Inference Time: 0.12350130081176758\n",
            "Inference Time: 0.1193552017211914\n",
            "Inference Time: 0.11080646514892578\n",
            "Inference Time: 0.11720585823059082\n",
            "Inference Time: 0.12813162803649902\n",
            "Inference Time: 0.11630654335021973\n",
            "Inference Time: 0.11867332458496094\n",
            "Inference Time: 0.12176680564880371\n",
            "Inference Time: 0.12785553932189941\n",
            "Inference Time: 0.1334385871887207\n",
            "Inference Time: 0.11818265914916992\n",
            "Inference Time: 0.1251850128173828\n",
            "Inference Time: 0.1107645034790039\n",
            "Inference Time: 0.12087726593017578\n",
            "Inference Time: 0.12332606315612793\n",
            "Inference Time: 0.12372231483459473\n",
            "Inference Time: 0.11532807350158691\n",
            "Inference Time: 0.1341564655303955\n",
            "Inference Time: 0.12228846549987793\n",
            "Inference Time: 0.11903643608093262\n",
            "Inference Time: 0.1129298210144043\n",
            "Inference Time: 0.13009285926818848\n",
            "Inference Time: 0.11291885375976562\n",
            "Inference Time: 0.12373042106628418\n",
            "Inference Time: 0.12895822525024414\n",
            "Inference Time: 0.13133811950683594\n",
            "Inference Time: 0.1168820858001709\n",
            "Inference Time: 0.11679220199584961\n",
            "Inference Time: 0.11629486083984375\n",
            "Inference Time: 0.12372517585754395\n",
            "Inference Time: 0.11710405349731445\n",
            "Inference Time: 0.12771081924438477\n",
            "Inference Time: 0.11406755447387695\n",
            "Inference Time: 0.12665748596191406\n",
            "Inference Time: 0.13231372833251953\n",
            "Inference Time: 0.11856389045715332\n",
            "Inference Time: 0.1175379753112793\n",
            "Inference Time: 0.12587571144104004\n",
            "Inference Time: 0.11311078071594238\n",
            "Inference Time: 0.1242671012878418\n",
            "Inference Time: 0.11672592163085938\n",
            "Inference Time: 0.12206363677978516\n",
            "Inference Time: 0.13120341300964355\n",
            "Inference Time: 0.12555646896362305\n",
            "Inference Time: 0.12644505500793457\n",
            "Inference Time: 0.11590862274169922\n",
            "Inference Time: 0.11662459373474121\n",
            "Inference Time: 0.11856770515441895\n",
            "Inference Time: 0.11822915077209473\n",
            "Inference Time: 0.11631917953491211\n",
            "Inference Time: 0.12447619438171387\n",
            "Inference Time: 0.12124013900756836\n",
            "Inference Time: 0.1122276782989502\n",
            "Inference Time: 0.12215900421142578\n",
            "Inference Time: 0.1298234462738037\n",
            "Inference Time: 0.12842607498168945\n",
            "Inference Time: 0.11373066902160645\n",
            "Inference Time: 0.11618852615356445\n",
            "Inference Time: 0.13460874557495117\n",
            "Inference Time: 0.1152944564819336\n",
            "Inference Time: 0.11558246612548828\n",
            "Inference Time: 0.11875391006469727\n",
            "Inference Time: 0.1127474308013916\n",
            "Inference Time: 0.12179780006408691\n",
            "Inference Time: 0.1266310214996338\n",
            "Inference Time: 0.11354684829711914\n",
            "Inference Time: 0.11758279800415039\n",
            "Inference Time: 0.12529611587524414\n",
            "Inference Time: 0.11829447746276855\n",
            "Inference Time: 0.11559677124023438\n",
            "Inference Time: 0.11625385284423828\n",
            "Inference Time: 0.12402796745300293\n",
            "Inference Time: 0.11603140830993652\n",
            "Inference Time: 0.12590575218200684\n",
            "Inference Time: 0.12483835220336914\n",
            "Inference Time: 0.13694524765014648\n",
            "Inference Time: 0.11122727394104004\n",
            "Inference Time: 0.12488603591918945\n",
            "Inference Time: 0.1270148754119873\n",
            "Inference Time: 0.12112188339233398\n",
            "Inference Time: 0.11913490295410156\n",
            "Inference Time: 0.11609148979187012\n",
            "Inference Time: 0.1084599494934082\n",
            "Inference Time: 0.11967587471008301\n",
            "Inference Time: 0.1376972198486328\n",
            "Inference Time: 0.1282486915588379\n",
            "Inference Time: 0.11050605773925781\n",
            "Inference Time: 0.11850929260253906\n",
            "Inference Time: 0.12130928039550781\n",
            "Inference Time: 0.12362360954284668\n",
            "Inference Time: 0.11901140213012695\n",
            "Inference Time: 0.11862373352050781\n",
            "Inference Time: 0.14153528213500977\n",
            "Inference Time: 0.12198758125305176\n",
            "Inference Time: 0.12364459037780762\n",
            "Inference Time: 0.12081551551818848\n",
            "Inference Time: 0.11422967910766602\n",
            "Inference Time: 0.12173199653625488\n",
            "Inference Time: 0.11323380470275879\n",
            "Inference Time: 0.1181027889251709\n",
            "Inference Time: 0.12823748588562012\n",
            "Inference Time: 0.12632250785827637\n",
            "Inference Time: 0.11698579788208008\n",
            "Inference Time: 0.11856532096862793\n",
            "Inference Time: 0.12798500061035156\n",
            "Inference Time: 0.11690115928649902\n",
            "Inference Time: 0.11062097549438477\n",
            "Inference Time: 0.12125420570373535\n",
            "Inference Time: 0.1161656379699707\n",
            "Inference Time: 0.13399958610534668\n",
            "Inference Time: 0.11526632308959961\n",
            "Inference Time: 0.11887669563293457\n",
            "Inference Time: 0.11267709732055664\n",
            "Inference Time: 0.11320900917053223\n",
            "Inference Time: 0.13600635528564453\n",
            "Inference Time: 0.12568354606628418\n",
            "Inference Time: 0.11851739883422852\n",
            "Inference Time: 0.13537168502807617\n",
            "Inference Time: 0.11814665794372559\n",
            "Inference Time: 0.12172174453735352\n",
            "Inference Time: 0.11202478408813477\n",
            "Inference Time: 0.12237811088562012\n",
            "Inference Time: 0.11076903343200684\n",
            "Inference Time: 0.1243133544921875\n",
            "Inference Time: 0.1231081485748291\n",
            "Inference Time: 0.12818288803100586\n",
            "Inference Time: 0.12065887451171875\n",
            "Inference Time: 0.11592793464660645\n",
            "Inference Time: 0.11948060989379883\n",
            "Inference Time: 0.12579703330993652\n",
            "Inference Time: 0.11917757987976074\n",
            "Inference Time: 0.12036776542663574\n",
            "Inference Time: 0.10999822616577148\n",
            "Inference Time: 0.11893844604492188\n",
            "Inference Time: 0.13844037055969238\n",
            "Inference Time: 0.11734771728515625\n",
            "Inference Time: 0.11641550064086914\n",
            "Inference Time: 0.11944437026977539\n",
            "Inference Time: 0.11669754981994629\n",
            "Inference Time: 0.12260603904724121\n",
            "Inference Time: 0.11395120620727539\n",
            "Inference Time: 0.12660646438598633\n",
            "Inference Time: 0.12299299240112305\n",
            "Inference Time: 0.11695647239685059\n",
            "Inference Time: 0.13326311111450195\n",
            "Inference Time: 0.12242913246154785\n",
            "Inference Time: 0.11967635154724121\n",
            "Inference Time: 0.11675071716308594\n",
            "Inference Time: 0.10986804962158203\n",
            "Inference Time: 0.11320209503173828\n",
            "Inference Time: 0.12305569648742676\n",
            "Inference Time: 0.12141609191894531\n",
            "Inference Time: 0.11183404922485352\n",
            "Inference Time: 0.11560249328613281\n",
            "Inference Time: 0.12273168563842773\n",
            "Inference Time: 0.11796307563781738\n",
            "Inference Time: 0.11779212951660156\n",
            "Inference Time: 0.11976408958435059\n",
            "Inference Time: 0.11334919929504395\n",
            "Inference Time: 0.1356675624847412\n",
            "Inference Time: 0.11690449714660645\n",
            "Inference Time: 0.13386178016662598\n",
            "Inference Time: 0.11429405212402344\n",
            "Inference Time: 0.11439132690429688\n",
            "Inference Time: 0.12757468223571777\n",
            "Inference Time: 0.11707544326782227\n",
            "Inference Time: 0.12856125831604004\n",
            "Inference Time: 0.1285555362701416\n",
            "Inference Time: 0.11357307434082031\n",
            "Inference Time: 0.12552595138549805\n",
            "Inference Time: 0.11914515495300293\n",
            "Inference Time: 0.12339448928833008\n",
            "Inference Time: 0.11547708511352539\n",
            "Inference Time: 0.11291360855102539\n",
            "Inference Time: 0.13270974159240723\n",
            "Inference Time: 0.13615989685058594\n",
            "Inference Time: 0.1225881576538086\n",
            "Inference Time: 0.12495541572570801\n",
            "Inference Time: 0.11994504928588867\n",
            "Inference Time: 0.11855959892272949\n",
            "Inference Time: 0.11722540855407715\n",
            "Inference Time: 0.12075257301330566\n",
            "Inference Time: 0.12209272384643555\n",
            "Inference Time: 0.13638615608215332\n",
            "Inference Time: 0.13286805152893066\n",
            "Inference Time: 0.12376999855041504\n",
            "Inference Time: 0.10885167121887207\n",
            "Inference Time: 0.12065291404724121\n",
            "Inference Time: 0.11224579811096191\n",
            "Inference Time: 0.1166837215423584\n",
            "Inference Time: 0.12370848655700684\n",
            "Inference Time: 0.11810016632080078\n",
            "Inference Time: 0.1264939308166504\n",
            "Inference Time: 0.11909794807434082\n",
            "Inference Time: 0.12393617630004883\n",
            "Inference Time: 0.11922073364257812\n",
            "Inference Time: 0.11165761947631836\n",
            "Inference Time: 0.1240694522857666\n",
            "Inference Time: 0.1139681339263916\n",
            "Inference Time: 0.13210487365722656\n",
            "Inference Time: 0.13817310333251953\n",
            "Inference Time: 0.11922049522399902\n",
            "Inference Time: 0.11765527725219727\n",
            "Inference Time: 0.11716866493225098\n",
            "Inference Time: 0.13211727142333984\n",
            "Inference Time: 0.11507987976074219\n",
            "Inference Time: 0.11001157760620117\n",
            "Inference Time: 0.13100028038024902\n",
            "Inference Time: 0.12750673294067383\n",
            "Inference Time: 0.12193155288696289\n",
            "Inference Time: 0.11658048629760742\n",
            "Inference Time: 0.11926436424255371\n",
            "Inference Time: 0.11628365516662598\n",
            "Inference Time: 0.11339592933654785\n",
            "Inference Time: 0.1266484260559082\n",
            "Inference Time: 0.12193703651428223\n",
            "Inference Time: 0.11379551887512207\n",
            "Inference Time: 0.1344754695892334\n",
            "Inference Time: 0.1153256893157959\n",
            "Inference Time: 0.11616206169128418\n",
            "Inference Time: 0.11757946014404297\n",
            "Inference Time: 0.1192786693572998\n",
            "Inference Time: 0.12309408187866211\n",
            "Inference Time: 0.11614465713500977\n",
            "Inference Time: 0.12706708908081055\n",
            "Inference Time: 0.13922452926635742\n",
            "Inference Time: 0.11484289169311523\n",
            "Inference Time: 0.12169885635375977\n",
            "Inference Time: 0.11424875259399414\n",
            "Inference Time: 0.11617112159729004\n",
            "Inference Time: 0.11777544021606445\n",
            "Inference Time: 0.11523628234863281\n",
            "Inference Time: 0.12007665634155273\n",
            "Inference Time: 0.11442828178405762\n",
            "Inference Time: 0.1344304084777832\n",
            "Inference Time: 0.12464332580566406\n",
            "Inference Time: 0.1178276538848877\n",
            "Inference Time: 0.123138427734375\n",
            "Inference Time: 0.11011505126953125\n",
            "Inference Time: 0.12337040901184082\n",
            "Inference Time: 0.12148571014404297\n",
            "Inference Time: 0.11439776420593262\n",
            "Inference Time: 0.12931180000305176\n",
            "Inference Time: 0.11922001838684082\n",
            "Inference Time: 0.12738823890686035\n",
            "Inference Time: 0.12053418159484863\n",
            "Inference Time: 0.12447357177734375\n",
            "Inference Time: 0.13004422187805176\n",
            "Inference Time: 0.11405253410339355\n",
            "Inference Time: 0.12451386451721191\n",
            "Inference Time: 0.13282132148742676\n",
            "Inference Time: 0.11983513832092285\n",
            "Inference Time: 0.11823749542236328\n",
            "Inference Time: 0.12073826789855957\n",
            "Inference Time: 0.12950515747070312\n",
            "Inference Time: 0.11618924140930176\n",
            "Inference Time: 0.1175532341003418\n",
            "Inference Time: 0.1209566593170166\n",
            "Inference Time: 0.12732362747192383\n",
            "Inference Time: 0.12952256202697754\n",
            "Inference Time: 0.11914467811584473\n",
            "Inference Time: 0.11681413650512695\n",
            "Inference Time: 0.11217546463012695\n",
            "Inference Time: 0.12437915802001953\n",
            "Inference Time: 0.12581801414489746\n",
            "Inference Time: 0.12373518943786621\n",
            "Inference Time: 0.1214606761932373\n",
            "Inference Time: 0.1341710090637207\n",
            "Inference Time: 0.1139218807220459\n",
            "Inference Time: 0.11553502082824707\n",
            "Inference Time: 0.1187751293182373\n",
            "Inference Time: 0.11958980560302734\n",
            "Inference Time: 0.12070107460021973\n",
            "Inference Time: 0.11898231506347656\n",
            "Inference Time: 0.13103508949279785\n",
            "Inference Time: 0.12960577011108398\n",
            "Inference Time: 0.11326432228088379\n",
            "Inference Time: 0.12399911880493164\n",
            "Inference Time: 0.11478662490844727\n",
            "Inference Time: 0.125901460647583\n",
            "Inference Time: 0.11708354949951172\n",
            "Inference Time: 0.12154006958007812\n",
            "Inference Time: 0.12237763404846191\n",
            "Inference Time: 0.1320028305053711\n",
            "Inference Time: 0.12745451927185059\n",
            "Inference Time: 0.12935876846313477\n",
            "Inference Time: 0.11333680152893066\n",
            "Inference Time: 0.12744760513305664\n",
            "Inference Time: 0.11333680152893066\n",
            "Inference Time: 0.12230134010314941\n",
            "Inference Time: 0.1142725944519043\n",
            "Inference Time: 0.12202978134155273\n",
            "Inference Time: 0.12000322341918945\n",
            "Inference Time: 0.1197509765625\n",
            "Inference Time: 0.12784433364868164\n",
            "Inference Time: 0.12468695640563965\n",
            "Inference Time: 0.11844944953918457\n",
            "Inference Time: 0.12106156349182129\n",
            "Inference Time: 0.11513137817382812\n",
            "Inference Time: 0.12188100814819336\n",
            "Inference Time: 0.12309575080871582\n",
            "Inference Time: 0.12241530418395996\n",
            "Inference Time: 0.11667752265930176\n",
            "Inference Time: 0.1179509162902832\n",
            "Inference Time: 0.12961649894714355\n",
            "Inference Time: 0.11733126640319824\n",
            "Inference Time: 0.12163448333740234\n",
            "Inference Time: 0.11735320091247559\n",
            "Inference Time: 0.12420415878295898\n",
            "Inference Time: 0.12341451644897461\n",
            "Inference Time: 0.11164021492004395\n",
            "Inference Time: 0.12510991096496582\n",
            "Inference Time: 0.11739349365234375\n",
            "Inference Time: 0.11387157440185547\n",
            "Inference Time: 0.1328258514404297\n",
            "Inference Time: 0.12010550498962402\n",
            "Inference Time: 0.13454961776733398\n",
            "Inference Time: 0.12163019180297852\n",
            "Inference Time: 0.11104822158813477\n",
            "Inference Time: 0.12499332427978516\n",
            "Inference Time: 0.11803698539733887\n",
            "Inference Time: 0.11919736862182617\n",
            "Inference Time: 0.11599111557006836\n",
            "Inference Time: 0.1160743236541748\n",
            "Inference Time: 0.12492609024047852\n",
            "Inference Time: 0.12476682662963867\n",
            "Inference Time: 0.12540078163146973\n",
            "Inference Time: 0.12398052215576172\n",
            "Inference Time: 0.12004494667053223\n",
            "Inference Time: 0.12705659866333008\n",
            "Inference Time: 0.10938882827758789\n",
            "Inference Time: 0.1219792366027832\n",
            "Inference Time: 0.10877799987792969\n",
            "Inference Time: 0.13635683059692383\n",
            "Inference Time: 0.12560105323791504\n",
            "Inference Time: 0.12061834335327148\n",
            "Inference Time: 0.11991453170776367\n",
            "Inference Time: 0.12040853500366211\n",
            "Inference Time: 0.12083244323730469\n",
            "Inference Time: 0.1225588321685791\n",
            "Inference Time: 0.12641310691833496\n",
            "Inference Time: 0.13187170028686523\n",
            "Inference Time: 0.12854957580566406\n",
            "Inference Time: 0.127793550491333\n",
            "Inference Time: 0.12382721900939941\n",
            "Inference Time: 0.12537932395935059\n",
            "Inference Time: 0.11609387397766113\n",
            "Inference Time: 0.12236428260803223\n",
            "Inference Time: 0.12109923362731934\n",
            "Inference Time: 0.12499284744262695\n",
            "Inference Time: 0.1292102336883545\n",
            "Inference Time: 0.11668205261230469\n",
            "Inference Time: 0.1118471622467041\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jPUsQMAOKg8M"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}