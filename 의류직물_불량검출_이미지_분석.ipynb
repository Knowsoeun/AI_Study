{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "의류직물 불량검출_이미지 분석.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "16_s0pU9c-1N2YuaOy509_91v0jPlV5rW",
      "authorship_tag": "ABX9TyMKF/VCOT9DPYsbWBe4KG6e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Knowsoeun/AI_Study/blob/main/%EC%9D%98%EB%A5%98%EC%A7%81%EB%AC%BC_%EB%B6%88%EB%9F%89%EA%B2%80%EC%B6%9C_%EC%9D%B4%EB%AF%B8%EC%A7%80_%EB%B6%84%EC%84%9D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "실습 환경 준비"
      ],
      "metadata": {
        "id": "Tu8Kp9u4C4oy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q42mESgtCqjr",
        "outputId": "4b1a9f87-367a-4230-a7d2-667843e35812"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python) (1.21.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xf7yAxPhdHax",
        "outputId": "ae902bb8-a11d-4e44-d3e2-ddb9c9ce2743"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2     #컴퓨터 비전 오픈소스 라이브러리\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import random\n",
        "import string\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "ram5reh8CusO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PATH_DEFECT = '/content/drive/MyDrive/AI스터디/dataset/Defect_images/Defect_images/'\n",
        "PATH_MASK = '/content/drive/MyDrive/AI스터디/dataset/Mask_images/Mask_images/'\n",
        "PATH_NODEFECT = '/content/drive/MyDrive/AI스터디/dataset/NODefect_images/NODefect_images/'"
      ],
      "metadata": {
        "id": "N_Zlhb2AX3Jt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset 불러오기"
      ],
      "metadata": {
        "id": "WIkv7Q73L0hS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(0)\n",
        "\n",
        "defect_list = glob.glob(PATH_DEFECT + '*.png')\n",
        "mask_list = glob.glob(PATH_MASK + '*.png')\n",
        "pass_list = glob.glob(PATH_NODEFECT + '**/*.png')\n",
        "\n",
        "# Match defect-mask pairs\n",
        "new_defect_list = list()\n",
        "new_mask_list = list()\n",
        "for defect in defect_list:\n",
        "    num = defect.split('/')[-1].split('_')[0]\n",
        "    for mask in mask_list:\n",
        "        num_mask = mask.split('/')[-1].split('_')[0]\n",
        "        if num == num_mask:\n",
        "            new_defect_list.append(defect)\n",
        "            new_mask_list.append(mask)\n",
        "            break\n",
        "defect_list = new_defect_list\n",
        "mask_list = new_mask_list"
      ],
      "metadata": {
        "id": "QcI7gBxeLztu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "첫 발송 데이터 생성"
      ],
      "metadata": {
        "id": "5L4P5lTfNKx0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The first dataset given\n",
        "if os.path.exists('/content/drive/MyDrive/AI스터디/dataset/1') is False:\n",
        "    os.mkdir('/content/drive/MyDrive/AI스터디/dataset/1')\n",
        "for file_name in pass_list + defect_list:\n",
        "    if random.randint(0, 9) < 2:\n",
        "        barcode = ''.join(random.choices(string.ascii_letters + string.digits, k=16))\n",
        "        shutil.copy2(file_name, '/content/drive/MyDrive/AI스터디/dataset/1/' + barcode + '.png')"
      ],
      "metadata": {
        "id": "IGPnTlGrL5sR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "두번째 데이터 생성"
      ],
      "metadata": {
        "id": "KvTxmw_nV0AM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The second dataset\n",
        "if os.path.exists('/content/drive/MyDrive/AI스터디/dataset/2') is False:\n",
        "    os.mkdir('/content/drive/MyDrive/AI스터디/dataset/2')\n",
        "if os.path.exists('/content/drive/MyDrive/AI스터디/dataset/2/OK') is False:\n",
        "    os.mkdir('/content/drive/MyDrive/AI스터디/dataset/2/OK')\n",
        "if os.path.exists('/content/drive/MyDrive/AI스터디/dataset/2/FAIL') is False:\n",
        "    os.mkdir('/content/drive/MyDrive/AI스터디/dataset/2/FAIL')\n",
        "idx = 0\n",
        "for file_name in pass_list:\n",
        "    img = cv2.imread(file_name)\n",
        "    height, width, _ = img.shape\n",
        "    step = height // 2\n",
        "\n",
        "    for i in range(width // step):\n",
        "        w = i * step\n",
        "        if w < width - height and random.randint(0, 9) < 2:\n",
        "            patch = img[:, w:w+height, :]\n",
        "            cv2.imwrite('/content/drive/MyDrive/AI스터디/dataset/2/OK/%04d.png' % idx, patch)\n",
        "            idx += 1 \n",
        "\n",
        "patch_list = list()\n",
        "for item in zip(defect_list, mask_list):\n",
        "    defect, mask = item\n",
        "\n",
        "    img_d = cv2.imread(defect)\n",
        "    img_m = cv2.imread(mask)\n",
        "\n",
        "    height, width, _ = img_d.shape\n",
        "    step = height // 2\n",
        "    for i in range(width // step):\n",
        "        w = i * step\n",
        "        if w < width - height:\n",
        "            patch = img_d[:, w:w+height, :]\n",
        "            patch_d = img_m[:, w:w+height, :]\n",
        "            if patch_d.sum() > 0:\n",
        "                patch_list.append(patch)\n",
        "\n",
        "random.shuffle(patch_list)\n",
        "patch_list_fraction = patch_list[:len(patch_list)//3]\n",
        "for idx, patch in enumerate(patch_list_fraction):\n",
        "    cv2.imwrite('/content/drive/MyDrive/AI스터디/dataset/2/FAIL/%04d.png' % idx, patch)"
      ],
      "metadata": {
        "id": "mvFBWjmmVyCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "세번째 데이터 생성"
      ],
      "metadata": {
        "id": "kXvUNMupWFzw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The third dataset\n",
        "if os.path.exists('/content/drive/MyDrive/AI스터디/dataset/3') is False:\n",
        "    os.mkdir('/content/drive/MyDrive/AI스터디/dataset/3')\n",
        "if os.path.exists('/content/drive/MyDrive/AI스터디/dataset/3/OK') is False:\n",
        "    os.mkdir('/content/drive/MyDrive/AI스터디/dataset/3/OK')\n",
        "if os.path.exists('/content/drive/MyDrive/AI스터디/dataset/3/FAIL') is False:\n",
        "    os.mkdir('/content/drive/MyDrive/AI스터디/dataset/3/FAIL')\n",
        "if os.path.exists('/content/drive/MyDrive/AI스터디/dataset/3/MASK') is False:\n",
        "    os.mkdir('/content/drive/MyDrive/AI스터디/dataset/3/MASK')\n",
        "idx = 0\n",
        "for file_name in pass_list:\n",
        "    img = cv2.imread(file_name)\n",
        "    height, width, _ = img.shape\n",
        "    step = height // 2\n",
        "\n",
        "    for i in range(width // step):\n",
        "        w = i * step\n",
        "        if w < width - height and random.randint(0, 9) < 3:\n",
        "            patch = img[:, w:w+height, :]\n",
        "            cv2.imwrite('/content/drive/MyDrive/AI스터디/dataset/3/OK/%04d.png' % idx, patch)\n",
        "            idx += 1 \n",
        "\n",
        "patch_pair_list = list()\n",
        "for item in zip(defect_list, mask_list):\n",
        "    defect, mask = item\n",
        "\n",
        "    img_d = cv2.imread(defect)\n",
        "    img_m = cv2.imread(mask)\n",
        "\n",
        "    height, width, _ = img_d.shape\n",
        "    step = height // 2\n",
        "    for i in range(width // step):\n",
        "        w = i * step\n",
        "        if w < width - height:\n",
        "            patch = img_d[:, w:w+height, :]\n",
        "            patch_d = img_m[:, w:w+height, :]\n",
        "\n",
        "            if patch_d.sum() > 0:\n",
        "                patch_pair_list.append((patch, patch_d))\n",
        "\n",
        "random.shuffle(patch_pair_list)\n",
        "for idx, pair in enumerate(patch_pair_list):\n",
        "    patch, patch_d = pair\n",
        "    cv2.imwrite('/content/drive/MyDrive/AI스터디/dataset/3/FAIL/%04d.png' % idx, patch)\n",
        "    cv2.imwrite('/content/drive/MyDrive/AI스터디/dataset/3/MASK/%04d.png' % idx, patch_d)"
      ],
      "metadata": {
        "id": "ouAAjB49YfIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "실전 데이터 생성"
      ],
      "metadata": {
        "id": "Du02GPRQWHN3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The test dataset\n",
        "if os.path.exists('/content/drive/MyDrive/AI스터디/data/') is False:\n",
        "    os.mkdir('/content/drive/MyDrive/AI스터디/data/')\n",
        "if os.path.exists('/content/drive/MyDrive/AI스터디/tfrecords/') is False:\n",
        "    os.mkdir('/content/drive/MyDrive/AI스터디/tfrecords/')\n",
        "if os.path.exists('/content/drive/MyDrive/AI스터디/model/') is False:\n",
        "    os.mkdir('/content/drive/MyDrive/AI스터디/model/')\n",
        "if os.path.exists('/content/drive/MyDrive/AI스터디/data/input_data') is False:\n",
        "    os.mkdir('/content/drive/MyDrive/AI스터디/data/input_data')\n",
        "if os.path.exists('/content/drive/MyDrive/AI스터디/data/output_csv') is False:\n",
        "    os.mkdir('/content/drive/MyDrive/AI스터디/data/output_csv')\n",
        "    \n",
        "idx = 0\n",
        "for file_name in pass_list:\n",
        "    img = cv2.imread(file_name)\n",
        "    height, width, _ = img.shape\n",
        "    step = height // 2\n",
        "\n",
        "    for i in range(width // step):\n",
        "        w = i * step\n",
        "        if w < width - height and random.randint(0, 9) < 5:\n",
        "            patch = img[:, w:w+height, :]\n",
        "            cv2.imwrite('/content/drive/MyDrive/AI스터디/data/input_data/ok_%04d.png' % idx, patch)\n",
        "            idx += 1 \n",
        "\n",
        "patch_pair_list = list()\n",
        "for item in zip(defect_list, mask_list):\n",
        "    defect, mask = item\n",
        "\n",
        "    img_d = cv2.imread(defect)\n",
        "    img_m = cv2.imread(mask)\n",
        "\n",
        "    height, width, _ = img_d.shape\n",
        "    step = height // 2\n",
        "    for i in range(width // step):\n",
        "        w = i * step\n",
        "        if w < width - height:\n",
        "            patch = img_d[:, w:w+height, :]\n",
        "            patch_d = img_m[:, w:w+height, :]\n",
        "\n",
        "            if patch_d.sum() > 0:\n",
        "                patch_pair_list.append((patch, patch_d))\n",
        "\n",
        "random.shuffle(patch_pair_list)\n",
        "for idx, pair in enumerate(patch_pair_list):\n",
        "    patch, patch_d = pair\n",
        "    cv2.imwrite('/content/drive/MyDrive/AI스터디/data/input_data/fail_%04d.png' % idx, patch)"
      ],
      "metadata": {
        "id": "6mlvcPQaWWSl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "실행 가능성 확인하기"
      ],
      "metadata": {
        "id": "qVf3vlELbHFR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "metadata": {
        "id": "OGSN2XQBcMXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "하이퍼파라미터"
      ],
      "metadata": {
        "id": "Xd5Kua-vbecn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 15  # 학습이 너무 느려서 15로 설정함\n",
        "\n",
        "DATASET_PATH = '/content/drive/MyDrive/AI스터디/dataset/2/'\n",
        "DATASET_OK_PATTERN = DATASET_PATH + 'OK/*.png'     # 정상\n",
        "DATASET_FAIL_PATTERN = DATASET_PATH + 'FAIL/*.png'  # 불량\n",
        "\n",
        "RESULT_SAVE_PATH = '/content/drive/MyDrive/AI스터디/results/'  # 알고리즘 결과"
      ],
      "metadata": {
        "id": "SnJQ62edNRwk"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "단순한 모델 설정"
      ],
      "metadata": {
        "id": "rUMXxH0zbsFM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Model():\n",
        "    return Sequential([Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 1)), #tensorflow 버전업으로 코드 변경\n",
        "                       MaxPool2D(),\n",
        "                       Conv2D(64, (3, 3), activation='relu'),\n",
        "                       MaxPool2D(),\n",
        "                       Conv2D(128, (3, 3), activation='relu'),\n",
        "                       MaxPool2D(),\n",
        "                       Conv2D(256, (3, 3), activation='relu'),\n",
        "                       MaxPool2D(),\n",
        "                       Flatten(),\n",
        "                       Dense(1, activation='sigmoid')])"
      ],
      "metadata": {
        "id": "JKK5GmHoXV08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터셋 불러오기"
      ],
      "metadata": {
        "id": "WQEcFUZabvkV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(file_name):\n",
        "    img = tf.io.read_file(file_name)\n",
        "    img = tf.image.decode_png(img, channels=1) #tensorflow 버전업으로 코드 변경\n",
        "    return tf.image.convert_image_dtype(img, tf.float32)"
      ],
      "metadata": {
        "id": "VUM63p2FbIeG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ok_list = glob.glob(DATASET_OK_PATTERN)\n",
        "ds_ok = tf.data.Dataset.list_files(ok_list)\n",
        "ds_ok_label = tf.data.Dataset.from_tensor_slices([0] * len(ok_list))\n",
        "\n",
        "ds_ok = ds_ok.map(preprocess)\n",
        "ds_ok = tf.data.Dataset.zip((ds_ok, ds_ok_label))\n",
        "\n",
        "fail_list = glob.glob(DATASET_FAIL_PATTERN)\n",
        "ds_fail = tf.data.Dataset.list_files(fail_list)\n",
        "ds_fail_label = tf.data.Dataset.from_tensor_slices([1] * len(fail_list))\n",
        "\n",
        "ds_fail = ds_fail.map(preprocess)\n",
        "ds_fail = tf.data.Dataset.zip((ds_fail, ds_fail_label))\n",
        "\n",
        "ds = tf.data.Dataset.concatenate(ds_ok, ds_fail)"
      ],
      "metadata": {
        "id": "6iW3_2IKP2o0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train, Valid 데이터셋 나누기"
      ],
      "metadata": {
        "id": "zlkj_J6lY0TI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds_size = len(ok_list) + len(fail_list)\n",
        "train_size = int(ds_size * 0.7)\n",
        "\n",
        "ds = ds.shuffle(ds_size)\n",
        "ds_train = ds.take(train_size).shuffle(1024, reshuffle_each_iteration=True).batch(32)\n",
        "ds_valid = ds.skip(train_size).batch(32)"
      ],
      "metadata": {
        "id": "Edg1jwhLcgEW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 생성 및 학습"
      ],
      "metadata": {
        "id": "J6MiRoO2Y4QW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model()\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "1BPa5JrEY21Y"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(ds_train, validation_data=ds_valid, epochs=EPOCHS)\n",
        "# Training 시키니 loss가 0.45에서 0.36으로 지속적으로 감소하였다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctcm9P6XY55w",
        "outputId": "438ae181-5f91-4546-d17d-594faee4e71a"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "21/21 [==============================] - 107s 5s/step - loss: 0.3403 - accuracy: 0.8805 - val_loss: 0.3178 - val_accuracy: 0.8908\n",
            "Epoch 2/15\n",
            "21/21 [==============================] - 106s 5s/step - loss: 0.3766 - accuracy: 0.8638 - val_loss: 0.3460 - val_accuracy: 0.8627\n",
            "Epoch 3/15\n",
            "21/21 [==============================] - 106s 5s/step - loss: 0.3371 - accuracy: 0.8865 - val_loss: 0.4077 - val_accuracy: 0.9049\n",
            "Epoch 4/15\n",
            "21/21 [==============================] - 107s 5s/step - loss: 0.3422 - accuracy: 0.8911 - val_loss: 0.3291 - val_accuracy: 0.8979\n",
            "Epoch 5/15\n",
            "21/21 [==============================] - 106s 5s/step - loss: 0.3354 - accuracy: 0.8654 - val_loss: 0.3893 - val_accuracy: 0.8732\n",
            "Epoch 6/15\n",
            "21/21 [==============================] - 107s 5s/step - loss: 0.3151 - accuracy: 0.8971 - val_loss: 0.2713 - val_accuracy: 0.9155\n",
            "Epoch 7/15\n",
            "21/21 [==============================] - 106s 5s/step - loss: 0.3017 - accuracy: 0.8926 - val_loss: 0.2986 - val_accuracy: 0.8768\n",
            "Epoch 8/15\n",
            "21/21 [==============================] - 107s 5s/step - loss: 0.3134 - accuracy: 0.8835 - val_loss: 0.3098 - val_accuracy: 0.8908\n",
            "Epoch 9/15\n",
            "21/21 [==============================] - 106s 5s/step - loss: 0.3504 - accuracy: 0.8699 - val_loss: 0.3608 - val_accuracy: 0.8838\n",
            "Epoch 10/15\n",
            "21/21 [==============================] - 106s 5s/step - loss: 0.3438 - accuracy: 0.8896 - val_loss: 0.3185 - val_accuracy: 0.8838\n",
            "Epoch 11/15\n",
            "21/21 [==============================] - 108s 5s/step - loss: 0.3146 - accuracy: 0.8850 - val_loss: 0.3658 - val_accuracy: 0.8732\n",
            "Epoch 12/15\n",
            "21/21 [==============================] - 110s 5s/step - loss: 0.3046 - accuracy: 0.8865 - val_loss: 0.3432 - val_accuracy: 0.8662\n",
            "Epoch 13/15\n",
            "21/21 [==============================] - 113s 5s/step - loss: 0.3147 - accuracy: 0.8896 - val_loss: 0.3047 - val_accuracy: 0.9225\n",
            "Epoch 14/15\n",
            "21/21 [==============================] - 109s 5s/step - loss: 0.3042 - accuracy: 0.8926 - val_loss: 0.4509 - val_accuracy: 0.8521\n",
            "Epoch 15/15\n",
            "21/21 [==============================] - 108s 5s/step - loss: 0.3537 - accuracy: 0.8775 - val_loss: 0.2967 - val_accuracy: 0.8979\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f58baabb110>"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "결과를 이미지로 저장"
      ],
      "metadata": {
        "id": "qjTfwjgkY7p_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mkdir(path):\n",
        "    if os.path.exists(path) is False:\n",
        "        os.mkdir(path)\n",
        "\n",
        "mkdir(RESULT_SAVE_PATH)\n",
        "mkdir(RESULT_SAVE_PATH + '/TP')  # True Positive\n",
        "mkdir(RESULT_SAVE_PATH + '/TN')  # True Negative\n",
        "mkdir(RESULT_SAVE_PATH + '/FP')  # False Positive \n",
        "mkdir(RESULT_SAVE_PATH + '/FN')  # False Negative \n",
        "\n",
        "index = 0\n",
        "for imgs, labels in ds_valid:\n",
        "    preds = model.predict(imgs)\n",
        "    for idx in range(imgs.shape[0]):\n",
        "        gt = labels[idx].numpy()\n",
        "        y = preds[idx]\n",
        "        \n",
        "        if gt == 1 and y > 0.5:\n",
        "            path = RESULT_SAVE_PATH + '/TP' # 제대로 검출한 것들(불량 검출)-1에 가까워야 잘 검출된 것이다.\n",
        "        elif gt == 1 and y <= 0.5:\n",
        "            path = RESULT_SAVE_PATH + '/FN' # 양품이라고 했는데 실제로 불량이었던 것들. 오검. \n",
        "        elif gt == 0 and y > 0.5:\n",
        "            path = RESULT_SAVE_PATH + '/FP' # 0이므로 오검한 것은 없다.\n",
        "        else:\n",
        "            path = RESULT_SAVE_PATH + '/TN' # 0.5에 가깝게 점수가 높은 것들을 보면 복잡하게 생긴 것들이 많다. \n",
        "                                            # 0.4점대랑 0.1점대랑 구분이 명확하게 되진 않았다.\n",
        "            \n",
        "        cv2.imwrite(path + '/%.4f_%04d.png' % (y, index), imgs[idx].numpy() * 255)\n",
        "        index +=1\n",
        "# 결과 이미지가 저장된 곳을 찾아가서 정밀도와 재현율을 구해보았다.\n",
        "# TP = 2, FN= 33, FP= 0, TN=249\n",
        "# 정밀도 = 1, 재현율 = 0.06"
      ],
      "metadata": {
        "id": "HILpeN87Y603"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " *정밀도*  \n",
        " 2/(2 + 0) = 1  \n",
        " 이를 해석해보자면, ‘불량으로 판정한 양품은 2개인데, 그 중 2명만 실제로 불량인 양품이다’라고 이해할 수 있다.   \n",
        " 따라서, 정밀도 측면에서 이 진단 키트의 정확성은 100%라고 볼 수 있다.\n",
        "\n",
        " "
      ],
      "metadata": {
        "id": "kiQ8kNnP_u5d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*재현율*  \n",
        "\n",
        "(positive 데이터를 negative로 잘못 판단하면 문제가 생기는 경우에 중요시된다.)  \n",
        "(재현율은 예를 들어 암 발병을 판단하는 경우에 암 환자를 음성으로 잘못 판단하는 경우 대가가 크기 때문에 FN을 낮추는데 초점을 맞춰야한다.)  \n",
        "2/(33+0)=0.06    \n",
        "재현율이 1% 미만이므로 좋은 모델이라고 볼 수 있다. "
      ],
      "metadata": {
        "id": "e6gAFnx_AGce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jg7GXI79_2oS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}